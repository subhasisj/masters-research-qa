{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "fine-tuning-language-task-adapters.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d1a25f4ac4b4d8eaa963c43fbc71bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4da16f65e48f4a9fa34e71c5721771d9",
              "IPY_MODEL_657145f3bca448259de4e0fe43d36d40",
              "IPY_MODEL_968789eb3e584794b5cb26ecbc8d4a48",
              "IPY_MODEL_fbf4e5636bc4487f88efe6141a32dacd",
              "IPY_MODEL_ea50b090d3b54a01947b731658d93a3b"
            ],
            "layout": "IPY_MODEL_7052f8f0bf634d53bbf51b1fcfe2d247"
          }
        },
        "4da16f65e48f4a9fa34e71c5721771d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e5adf9048b44b4e87a41245ec2a2d10",
            "placeholder": "​",
            "style": "IPY_MODEL_b1cf85a910a14098a66e65dc722b0480",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "657145f3bca448259de4e0fe43d36d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_66818576e9964fee8df8d554cfd49730",
            "placeholder": "​",
            "style": "IPY_MODEL_9524facb7f68439b8b1e6fe207a872e8",
            "value": ""
          }
        },
        "968789eb3e584794b5cb26ecbc8d4a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_19f9489fd079418b82754fba48d72161",
            "style": "IPY_MODEL_0ac9f78d4a4c4204986fe4a10e9fbe0c",
            "tooltip": ""
          }
        },
        "fbf4e5636bc4487f88efe6141a32dacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fde4a6eea9924c0f849a28a4f3fd9c37",
            "placeholder": "​",
            "style": "IPY_MODEL_77dfde69861e4e9c86cbce1eb3431ab3",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. <br> <i>Logging in with your username and password is deprecated and\nwon't be possible anymore in the near future. You can still use them for now by\nclicking below.</i> </center>"
          }
        },
        "ea50b090d3b54a01947b731658d93a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Use password",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_2277791928e34134bd8e2e58049622df",
            "style": "IPY_MODEL_02f45fa0d9524c77aa1f3dbb59f610e6",
            "tooltip": ""
          }
        },
        "7052f8f0bf634d53bbf51b1fcfe2d247": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "4e5adf9048b44b4e87a41245ec2a2d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1cf85a910a14098a66e65dc722b0480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66818576e9964fee8df8d554cfd49730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9524facb7f68439b8b1e6fe207a872e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19f9489fd079418b82754fba48d72161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac9f78d4a4c4204986fe4a10e9fbe0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "fde4a6eea9924c0f849a28a4f3fd9c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77dfde69861e4e9c86cbce1eb3431ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2277791928e34134bd8e2e58049622df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02f45fa0d9524c77aa1f3dbb59f610e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e291da1b720949c1ab24c18250f52e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1baba6e0c054ceab83e606efa4273e6",
              "IPY_MODEL_4e005507d8bf4f39ab38e3b0dc634e06",
              "IPY_MODEL_fd4e9584d87e48f5bcc7b115533e0a38"
            ],
            "layout": "IPY_MODEL_691827adf40340ad9ef73d5672463df6"
          }
        },
        "f1baba6e0c054ceab83e606efa4273e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f942932158a04b6bb712f623f8b092d6",
            "placeholder": "​",
            "style": "IPY_MODEL_6b4e7cc1024a4e32908c0e78c12127f7",
            "value": "100%"
          }
        },
        "4e005507d8bf4f39ab38e3b0dc634e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9be647d2ade4c5baa86c260f6110dbd",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd0b7e3313cb4d50a4ba6b93df518314",
            "value": 86
          }
        },
        "fd4e9584d87e48f5bcc7b115533e0a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02606f9bb2a4482a123c0ea9ae7dad3",
            "placeholder": "​",
            "style": "IPY_MODEL_07417eaec5de477480977a5996be862c",
            "value": " 86/86 [00:54&lt;00:00,  1.49ba/s]"
          }
        },
        "691827adf40340ad9ef73d5672463df6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f942932158a04b6bb712f623f8b092d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b4e7cc1024a4e32908c0e78c12127f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9be647d2ade4c5baa86c260f6110dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd0b7e3313cb4d50a4ba6b93df518314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e02606f9bb2a4482a123c0ea9ae7dad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07417eaec5de477480977a5996be862c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7591dec07c241a6a09d003e4cabc833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18a3e1782eac4c2da0ee432b19c5cc81",
              "IPY_MODEL_683c36d133c04fff9f2daeb0d0808121",
              "IPY_MODEL_b771570231b24d4d9c94cd9f281068cb"
            ],
            "layout": "IPY_MODEL_1517325e09cf4cb097ea07b4c1a7dc30"
          }
        },
        "18a3e1782eac4c2da0ee432b19c5cc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d2a6cde8e2b4e698e42f145f710954d",
            "placeholder": "​",
            "style": "IPY_MODEL_4fc766bff6b94c289d96dcf11ca6b1b4",
            "value": "100%"
          }
        },
        "683c36d133c04fff9f2daeb0d0808121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f78a23cbde462589897a8b5d57e86c",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_716f2eaf16c04b20b3544eb644d15a4c",
            "value": 35
          }
        },
        "b771570231b24d4d9c94cd9f281068cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54957f6b683a4500bae62eee82f35bae",
            "placeholder": "​",
            "style": "IPY_MODEL_ee03363371154acb95a63acce3124913",
            "value": " 35/35 [00:22&lt;00:00,  1.45ba/s]"
          }
        },
        "1517325e09cf4cb097ea07b4c1a7dc30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d2a6cde8e2b4e698e42f145f710954d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fc766bff6b94c289d96dcf11ca6b1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9f78a23cbde462589897a8b5d57e86c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "716f2eaf16c04b20b3544eb644d15a4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54957f6b683a4500bae62eee82f35bae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee03363371154acb95a63acce3124913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rj19q83peaKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hfCDf7-wfVJ0",
        "outputId": "4f5453e4-7237-4ae6-8758-6a71d8619436",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T11:21:08.457469Z",
          "iopub.execute_input": "2022-05-20T11:21:08.457728Z",
          "iopub.status.idle": "2022-05-20T11:21:09.153772Z",
          "shell.execute_reply.started": "2022-05-20T11:21:08.457690Z",
          "shell.execute_reply": "2022-05-20T11:21:09.152846Z"
        },
        "trusted": true,
        "id": "yF4uF29leXky",
        "outputId": "2e9672bc-7981-4fa3-b5ed-cbeac8e1b3f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat May 21 07:22:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets adapter-transformers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:01:44.810422Z",
          "iopub.execute_input": "2022-05-20T16:01:44.811154Z",
          "iopub.status.idle": "2022-05-20T16:02:02.448422Z",
          "shell.execute_reply.started": "2022-05-20T16:01:44.811063Z",
          "shell.execute_reply": "2022-05-20T16:02:02.447567Z"
        },
        "trusted": true,
        "id": "DlsCiZMaeXk1",
        "outputId": "14b854a9-bf6f-4d43-b4d2-60e866d0a26e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.2.2-py3-none-any.whl (346 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 37.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 71 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 81 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 133 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 143 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 153 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 163 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 174 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 184 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 194 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 204 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 215 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 225 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 235 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 245 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 256 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 266 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 276 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 286 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 296 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 307 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 317 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 327 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 337 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 346 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting adapter-transformers\n",
            "  Downloading adapter_transformers-3.0.1-py3-none-any.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 58.8 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: dill<0.3.5 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 49.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 54.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 40.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 38.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 56.0 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 62.5 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=17f2d0bdb3d14d9957bd2696162ca1d53fef748c36da5275b5301fd88042cd02\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, responses, huggingface-hub, datasets, adapter-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed adapter-transformers-3.0.1 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.2 frozenlist-1.3.0 fsspec-2022.5.0 huggingface-hub-0.6.0 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.53 tokenizers-0.12.1 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade --force-reinstall pyarrow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T11:20:57.265032Z",
          "iopub.execute_input": "2022-05-20T11:20:57.265330Z",
          "iopub.status.idle": "2022-05-20T11:21:00.815623Z",
          "shell.execute_reply.started": "2022-05-20T11:20:57.265288Z",
          "shell.execute_reply": "2022-05-20T11:21:00.814483Z"
        },
        "trusted": true,
        "id": "IeQfqcjreXk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "HhMWcXKNhp1T",
        "outputId": "9a0b150a-1ee1-4e86-ae56-0cd669cc4ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415,
          "referenced_widgets": [
            "1d1a25f4ac4b4d8eaa963c43fbc71bfe",
            "4da16f65e48f4a9fa34e71c5721771d9",
            "657145f3bca448259de4e0fe43d36d40",
            "968789eb3e584794b5cb26ecbc8d4a48",
            "fbf4e5636bc4487f88efe6141a32dacd",
            "ea50b090d3b54a01947b731658d93a3b",
            "7052f8f0bf634d53bbf51b1fcfe2d247",
            "4e5adf9048b44b4e87a41245ec2a2d10",
            "b1cf85a910a14098a66e65dc722b0480",
            "66818576e9964fee8df8d554cfd49730",
            "9524facb7f68439b8b1e6fe207a872e8",
            "19f9489fd079418b82754fba48d72161",
            "0ac9f78d4a4c4204986fe4a10e9fbe0c",
            "fde4a6eea9924c0f849a28a4f3fd9c37",
            "77dfde69861e4e9c86cbce1eb3431ab3",
            "2277791928e34134bd8e2e58049622df",
            "02f45fa0d9524c77aa1f3dbb59f610e6"
          ]
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
            "\n",
            "git config --global credential.helper store\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "A4X5F9ZdeXk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from transformers.adapters.composition import Fuse\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForQuestionAnswering,\n",
        "    AutoModelWithHeads,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        "    default_data_collator,\n",
        "    PreTrainedTokenizerFast,\n",
        "    AutoAdapterModel,\n",
        "    AdapterConfig,\n",
        "    AutoModelForQuestionAnswering,\n",
        ")\n",
        "from transformers import AdapterConfig\n",
        "from transformers.adapters.composition import Stack\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:03:59.647650Z",
          "iopub.execute_input": "2022-05-20T16:03:59.647910Z",
          "iopub.status.idle": "2022-05-20T16:04:05.414053Z",
          "shell.execute_reply.started": "2022-05-20T16:03:59.647882Z",
          "shell.execute_reply": "2022-05-20T16:04:05.413337Z"
        },
        "trusted": true,
        "id": "s7c8vVIdeXk3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "6h7q2I96eXk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def squad_json_to_dataframe_train(input_file_path, record_path = ['data','paragraphs','qas','answers'],\n",
        "                           verbose = 1):\n",
        "    \"\"\"\n",
        "    input_file_path: path to the squad json file.\n",
        "    record_path: path to deepest level in json file default value is\n",
        "    ['data','paragraphs','qas','answers']\n",
        "    verbose: 0 to suppress it default is 1\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(\"Reading the json file\")    \n",
        "    file = json.loads(open(input_file_path).read())\n",
        "    if verbose:\n",
        "        print(\"processing...\")\n",
        "    # parsing different level's in the json file\n",
        "    js = pd.io.json.json_normalize(file , record_path )\n",
        "    m = pd.io.json.json_normalize(file, record_path[:-1] )\n",
        "    r = pd.io.json.json_normalize(file,record_path[:-2])\n",
        "    \n",
        "    #combining it into single dataframe\n",
        "    idx = np.repeat(r['context'].values, r.qas.str.len())\n",
        "    ndx  = np.repeat(m['id'].values,m['answers'].str.len())\n",
        "    m['context'] = idx\n",
        "    js['q_idx'] = ndx\n",
        "    main = pd.concat([ m[['id','question','context']].set_index('id'),js.set_index('q_idx')],1,sort=False).reset_index()\n",
        "    main['c_id'] = main['context'].factorize()[0]\n",
        "    if verbose:\n",
        "        print(\"shape of the dataframe is {}\".format(main.shape))\n",
        "        print(\"Done\")\n",
        "    return main"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:04:20.989850Z",
          "iopub.execute_input": "2022-05-20T16:04:20.990223Z",
          "iopub.status.idle": "2022-05-20T16:04:21.009601Z",
          "shell.execute_reply.started": "2022-05-20T16:04:20.990180Z",
          "shell.execute_reply": "2022-05-20T16:04:21.008484Z"
        },
        "trusted": true,
        "id": "TAjaORuOeXk4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "v3T7itwWgNjF",
        "outputId": "12734394-4519-4e98-9c0d-769d1898fdd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training data\n",
        "language = 'hi'\n",
        "input_file_path = f'./drive/MyDrive/Colab Files/squad.translate.train.en-{language}.json'\n",
        "record_path = ['data','paragraphs','qas','answers']\n",
        "train = squad_json_to_dataframe_train(input_file_path=input_file_path,record_path=record_path,verbose=0)\n",
        "\n",
        "def get_answers(x):\n",
        "    start = x[0]\n",
        "    text = x[1]\n",
        "    return {\n",
        "        'answer_start': [start],\n",
        "        'text': [text]\n",
        "    }\n",
        "\n",
        "train['answers'] = train[['answer_start', 'text']].apply(get_answers, axis=1)\n",
        "pd.set_option('display.max_colwidth',None)\n",
        "train.head(1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:04:21.146454Z",
          "iopub.execute_input": "2022-05-20T16:04:21.146771Z",
          "iopub.status.idle": "2022-05-20T16:04:39.573385Z",
          "shell.execute_reply.started": "2022-05-20T16:04:21.146735Z",
          "shell.execute_reply": "2022-05-20T16:04:39.572613Z"
        },
        "trusted": true,
        "id": "dQwh86oAeXk5",
        "outputId": "a5ff9e01-787a-4927-a015-b4f0cd55ed29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      index                                 question  \\\n",
              "0  57283b4c3acd2414000df76d  जब लंदन यहूदी फोरम स्थापित किया गया था?   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              context  \\\n",
              "0  उत्तरी लंदन में स्टैमफोर्ड हिल, स्टैनमोर, गोल्डर्स ग्रीन, फिंचली, हैम्पस्टेड, हेंडन और एडगवेयर में महत्वपूर्ण यहूदी समुदायों के साथ अधिकांश ब्रिटिश यहूदी लंदन में रहते हैं। लंदन शहर के Bevis मार्क्स आराधनालय लंदन के ऐतिहासिक Sephardic यहूदी समुदाय से सम्बद्ध है। यह यूरोप का एकमात्र ऐसा आराधनालय है जिसने 300 वर्षों से लगातार नियमित सेवाओं का आयोजन किया है। स्टैनमोर और कैनन्स पार्क सिनेगॉग की 1998 में पूरे यूरोप में किसी भी ऑर्थोडॉक्स आराधनालय की सबसे बड़ी सदस्यता है, 1998 में इलफ़र्ड सिनेगॉग (लंदन में भी) से आगे निकल गया। समुदाय ने जवाब में 2006 में लंदन यहूदी फोरम की स्थापना की। विकसित लंदन सरकार के बढ़ते महत्व के लिए।   \n",
              "\n",
              "   answer_start  text  c_id                                    answers  \n",
              "0           546  2006     0  {'answer_start': [546], 'text': ['2006']}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57ce8945-ec9a-40e5-88cb-a86ef791ec4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>57283b4c3acd2414000df76d</td>\n",
              "      <td>जब लंदन यहूदी फोरम स्थापित किया गया था?</td>\n",
              "      <td>उत्तरी लंदन में स्टैमफोर्ड हिल, स्टैनमोर, गोल्डर्स ग्रीन, फिंचली, हैम्पस्टेड, हेंडन और एडगवेयर में महत्वपूर्ण यहूदी समुदायों के साथ अधिकांश ब्रिटिश यहूदी लंदन में रहते हैं। लंदन शहर के Bevis मार्क्स आराधनालय लंदन के ऐतिहासिक Sephardic यहूदी समुदाय से सम्बद्ध है। यह यूरोप का एकमात्र ऐसा आराधनालय है जिसने 300 वर्षों से लगातार नियमित सेवाओं का आयोजन किया है। स्टैनमोर और कैनन्स पार्क सिनेगॉग की 1998 में पूरे यूरोप में किसी भी ऑर्थोडॉक्स आराधनालय की सबसे बड़ी सदस्यता है, 1998 में इलफ़र्ड सिनेगॉग (लंदन में भी) से आगे निकल गया। समुदाय ने जवाब में 2006 में लंदन यहूदी फोरम की स्थापना की। विकसित लंदन सरकार के बढ़ते महत्व के लिए।</td>\n",
              "      <td>546</td>\n",
              "      <td>2006</td>\n",
              "      <td>0</td>\n",
              "      <td>{'answer_start': [546], 'text': ['2006']}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57ce8945-ec9a-40e5-88cb-a86ef791ec4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57ce8945-ec9a-40e5-88cb-a86ef791ec4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57ce8945-ec9a-40e5-88cb-a86ef791ec4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation data\n",
        "language = 'hi'\n",
        "input_file_path = f'./drive/MyDrive/Colab Files/squad.translate.dev.en-{language}.json'\n",
        "record_path = ['data','paragraphs','qas','answers']\n",
        "dev = squad_json_to_dataframe_train(input_file_path=input_file_path,record_path=record_path,verbose=0)\n",
        "dev['answers'] = dev[['answer_start', 'text']].apply(get_answers, axis=1)\n",
        "pd.set_option('display.max_colwidth',None)\n",
        "dev.head(1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:04:39.576546Z",
          "iopub.execute_input": "2022-05-20T16:04:39.576946Z",
          "iopub.status.idle": "2022-05-20T16:04:47.030775Z",
          "shell.execute_reply.started": "2022-05-20T16:04:39.576913Z",
          "shell.execute_reply": "2022-05-20T16:04:47.030079Z"
        },
        "trusted": true,
        "id": "ONdr5JPleXk6",
        "outputId": "bfdedf6e-21a7-4d7a-f2d5-ba9de183a3e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      index                                   question  \\\n",
              "0  56e1c9bfe3433e1400423196  बहुपद समय में कमी क्या इसका एक उदाहरण है?   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 context  \\\n",
              "0  कमी की अवधारणा का उपयोग करके कई जटिलता वर्गों को परिभाषित किया गया है। एक कमी एक समस्या का दूसरी समस्या में परिवर्तन है। यह एक समस्या की अनौपचारिक धारणा को कम से कम एक और समस्या के रूप में मुश्किल बनाता है। उदाहरण के लिए, यदि कोई समस्या Y के लिए एल्गोरिथ्म का उपयोग करके X को हल किया जा सकता है, तो X, Y से अधिक कठिन नहीं है, और हम कहते हैं कि X, Y को कम कर देता है। कई अलग-अलग प्रकार के कटौती हैं, जिनके आधार पर कटौती की विधि, जैसे कि कुक रिडक्शन, कार्प रिडक्शन और लेविन रिडक्शन, और पोलिनेशन-टाइम रिडक्शन या लॉग-स्पेस रिडक्शन जैसी कटौती की जटिलता पर बाध्य होती है।   \n",
              "\n",
              "   answer_start             text  c_id  \\\n",
              "0           378  प्रकार के कटौती     0   \n",
              "\n",
              "                                                answers  \n",
              "0  {'answer_start': [378], 'text': ['प्रकार के कटौती']}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a300a151-58b9-4f6c-9065-7bd46bd1da8a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>text</th>\n",
              "      <th>c_id</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56e1c9bfe3433e1400423196</td>\n",
              "      <td>बहुपद समय में कमी क्या इसका एक उदाहरण है?</td>\n",
              "      <td>कमी की अवधारणा का उपयोग करके कई जटिलता वर्गों को परिभाषित किया गया है। एक कमी एक समस्या का दूसरी समस्या में परिवर्तन है। यह एक समस्या की अनौपचारिक धारणा को कम से कम एक और समस्या के रूप में मुश्किल बनाता है। उदाहरण के लिए, यदि कोई समस्या Y के लिए एल्गोरिथ्म का उपयोग करके X को हल किया जा सकता है, तो X, Y से अधिक कठिन नहीं है, और हम कहते हैं कि X, Y को कम कर देता है। कई अलग-अलग प्रकार के कटौती हैं, जिनके आधार पर कटौती की विधि, जैसे कि कुक रिडक्शन, कार्प रिडक्शन और लेविन रिडक्शन, और पोलिनेशन-टाइम रिडक्शन या लॉग-स्पेस रिडक्शन जैसी कटौती की जटिलता पर बाध्य होती है।</td>\n",
              "      <td>378</td>\n",
              "      <td>प्रकार के कटौती</td>\n",
              "      <td>0</td>\n",
              "      <td>{'answer_start': [378], 'text': ['प्रकार के कटौती']}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a300a151-58b9-4f6c-9065-7bd46bd1da8a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a300a151-58b9-4f6c-9065-7bd46bd1da8a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a300a151-58b9-4f6c-9065-7bd46bd1da8a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tds = Dataset.from_pandas(train)\n",
        "vds = Dataset.from_pandas(dev)\n",
        "\n",
        "\n",
        "squad_hi = DatasetDict()\n",
        "\n",
        "squad_hi['train'] = tds\n",
        "squad_hi['validation'] = vds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:04:47.032236Z",
          "iopub.execute_input": "2022-05-20T16:04:47.032637Z",
          "iopub.status.idle": "2022-05-20T16:04:47.107415Z",
          "shell.execute_reply.started": "2022-05-20T16:04:47.032599Z",
          "shell.execute_reply": "2022-05-20T16:04:47.106689Z"
        },
        "trusted": true,
        "id": "GAQs8XkXeXk6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squad_hi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:04:47.109307Z",
          "iopub.execute_input": "2022-05-20T16:04:47.109566Z",
          "iopub.status.idle": "2022-05-20T16:04:47.120074Z",
          "shell.execute_reply.started": "2022-05-20T16:04:47.109521Z",
          "shell.execute_reply": "2022-05-20T16:04:47.119312Z"
        },
        "trusted": true,
        "id": "vqYYUd5beXk7",
        "outputId": "49b3a08f-27e6-4f08-859f-2a8793834ba4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['index', 'question', 'context', 'answer_start', 'text', 'c_id', 'answers'],\n",
              "        num_rows: 85804\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['index', 'question', 'context', 'answer_start', 'text', 'c_id', 'answers'],\n",
              "        num_rows: 34111\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# squad_en = load_dataset(\"squad\")\n",
        "# squad_en"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:04:47.121309Z",
          "iopub.execute_input": "2022-05-20T16:04:47.121977Z",
          "iopub.status.idle": "2022-05-20T16:05:05.585099Z",
          "shell.execute_reply.started": "2022-05-20T16:04:47.121940Z",
          "shell.execute_reply": "2022-05-20T16:05:05.584357Z"
        },
        "trusted": true,
        "id": "JrQ94MLoeXk7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create QA Features"
      ],
      "metadata": {
        "id": "D2q5L0zeeXk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "assert isinstance(tokenizer, PreTrainedTokenizerFast)\n",
        "pad_on_right = tokenizer.padding_side == \"right\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:05:05.586519Z",
          "iopub.execute_input": "2022-05-20T16:05:05.587055Z",
          "iopub.status.idle": "2022-05-20T16:05:22.730261Z",
          "shell.execute_reply.started": "2022-05-20T16:05:05.586995Z",
          "shell.execute_reply": "2022-05-20T16:05:22.729049Z"
        },
        "trusted": true,
        "id": "a2ZrHlZaeXk8",
        "outputId": "367987ba-e20e-452d-80ea-8df0b4fcf169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/xlm-roberta-base/resolve/main/sentencepiece.bpe.model from cache at /root/.cache/huggingface/transformers/9df9ae4442348b73950203b63d1b8ed2d18eba68921872aee0c3a9d05b9673c6.00628a9eeb8baf4080d44a0abe9fe8057893de20c7cb6e6423cddbf452f7d4d8\n",
            "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/daeda8d936162ca65fe6dd158ecce1d8cb56c17d89b78ab86be1558eaef1d76a.a984cf52fc87644bd4a2165f1e07e0ac880272c1e82d648b4674907056912bd7\n",
            "loading file https://huggingface.co/xlm-roberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/xlm-roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/xlm-roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/xlm-roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/87683eb92ea383b0475fecf99970e950a03c9ff5e51648d6eee56fb754612465.dfaaaedc7c1c475302398f09706cbb21e23951b73c6e2b3162c1c8a99bb3b62a\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"xlm-roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.\n",
        "def prepare_train_features(examples):\n",
        "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
        "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
        "    # left whitespace\n",
        "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
        "\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples\n",
        "\n",
        "def prepare_validation_features(examples):\n",
        "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
        "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
        "    # left whitespace\n",
        "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
        "\n",
        "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\" if pad_on_right else \"context\"],\n",
        "        examples[\"context\" if pad_on_right else \"question\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_index = 1 if pad_on_right else 0\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"index\"][sample_index])\n",
        "\n",
        "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
        "        # position is part of the context or not.\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:05:22.735493Z",
          "iopub.execute_input": "2022-05-20T16:05:22.735966Z",
          "iopub.status.idle": "2022-05-20T16:05:22.776834Z",
          "shell.execute_reply.started": "2022-05-20T16:05:22.735921Z",
          "shell.execute_reply": "2022-05-20T16:05:22.775967Z"
        },
        "trusted": true,
        "id": "yWzQ-_AieXk8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# squad = squad.map(\n",
        "#     prepare_train_features, batched=True, remove_columns=squad[\"train\"].column_names\n",
        "# )\n",
        "\n",
        "# squad_en = squad_en.map(\n",
        "#     prepare_train_features, batched=True, remove_columns=squad_en[\"train\"].column_names\n",
        "# )\n",
        "\n",
        "squad_hi = squad_hi.map(\n",
        "    prepare_train_features, batched=True, remove_columns=squad_hi[\"train\"].column_names\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:05:22.782556Z",
          "iopub.execute_input": "2022-05-20T16:05:22.785217Z",
          "iopub.status.idle": "2022-05-20T16:07:04.543165Z",
          "shell.execute_reply.started": "2022-05-20T16:05:22.785179Z",
          "shell.execute_reply": "2022-05-20T16:07:04.542473Z"
        },
        "trusted": true,
        "id": "vVOVhLzOeXk9",
        "outputId": "a9065d7c-6c4d-482f-a82d-3e978f147070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e291da1b720949c1ab24c18250f52e93",
            "f1baba6e0c054ceab83e606efa4273e6",
            "4e005507d8bf4f39ab38e3b0dc634e06",
            "fd4e9584d87e48f5bcc7b115533e0a38",
            "691827adf40340ad9ef73d5672463df6",
            "f942932158a04b6bb712f623f8b092d6",
            "6b4e7cc1024a4e32908c0e78c12127f7",
            "d9be647d2ade4c5baa86c260f6110dbd",
            "fd0b7e3313cb4d50a4ba6b93df518314",
            "e02606f9bb2a4482a123c0ea9ae7dad3",
            "07417eaec5de477480977a5996be862c",
            "c7591dec07c241a6a09d003e4cabc833",
            "18a3e1782eac4c2da0ee432b19c5cc81",
            "683c36d133c04fff9f2daeb0d0808121",
            "b771570231b24d4d9c94cd9f281068cb",
            "1517325e09cf4cb097ea07b4c1a7dc30",
            "9d2a6cde8e2b4e698e42f145f710954d",
            "4fc766bff6b94c289d96dcf11ca6b1b4",
            "b9f78a23cbde462589897a8b5d57e86c",
            "716f2eaf16c04b20b3544eb644d15a4c",
            "54957f6b683a4500bae62eee82f35bae",
            "ee03363371154acb95a63acce3124913"
          ]
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e291da1b720949c1ab24c18250f52e93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/35 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7591dec07c241a6a09d003e4cabc833"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model and Adapters\n",
        "\n",
        "### Enable EN only for training"
      ],
      "metadata": {
        "id": "pMAM-EvueXk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(f'./drive/MyDrive/Colab Files/models/{language}-adapter-en-trained')\n",
        "config = AdapterConfig.load(\"pfeiffer\",non_linearity=\"relu\", reduction_factor=2)\n",
        "adapter_name_1 = model.load_adapter(f'./drive/MyDrive/Colab Files/models/{language}-adapter-en-trained/en', config=config,model_name='xlm-roberta-base')\n",
        "adapter_name_2 = model.load_adapter(f'./drive/MyDrive/Colab Files/models/{language}-adapter-en-trained/hi',config=config)\n",
        "task_adapter = model.load_adapter(\"AdapterHub/roberta-base-pf-squad\", source=\"hf\",load_as = 'pfeiffer_xlm_base')\n",
        "model.set_active_adapters(adapter_name_2,task_adapter)\n",
        "model.train_adapter('pfeiffer_xlm_base')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:07:04.544532Z",
          "iopub.execute_input": "2022-05-20T16:07:04.544802Z",
          "iopub.status.idle": "2022-05-20T16:09:37.670591Z",
          "shell.execute_reply.started": "2022-05-20T16:07:04.544766Z",
          "shell.execute_reply": "2022-05-20T16:09:37.669853Z"
        },
        "trusted": true,
        "id": "9Kvtu-lreXk9",
        "outputId": "41e6c6d1-63ad-41d0-8482-d260915eed86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained/config.json\n",
            "Model config XLMRobertaConfig {\n",
            "  \"_name_or_path\": \"./drive/MyDrive/Colab Files/models/hi-adapter-en-trained\",\n",
            "  \"adapters\": {\n",
            "    \"adapters\": {\n",
            "      \"en\": \"16eaa0b5fae9ed68\",\n",
            "      \"hi\": \"16eaa0b5fae9ed68\",\n",
            "      \"pfeiffer_xlm_base\": \"9076f36a74755ac4\"\n",
            "    },\n",
            "    \"config_map\": {\n",
            "      \"16eaa0b5fae9ed68\": {\n",
            "        \"adapter_residual_before_ln\": false,\n",
            "        \"cross_adapter\": false,\n",
            "        \"factorized_phm_W\": true,\n",
            "        \"factorized_phm_rule\": false,\n",
            "        \"hypercomplex_nonlinearity\": \"glorot-uniform\",\n",
            "        \"init_weights\": \"bert\",\n",
            "        \"inv_adapter\": \"nice\",\n",
            "        \"inv_adapter_reduction_factor\": 2,\n",
            "        \"is_parallel\": false,\n",
            "        \"learn_phm\": true,\n",
            "        \"leave_out\": [],\n",
            "        \"ln_after\": false,\n",
            "        \"ln_before\": false,\n",
            "        \"mh_adapter\": false,\n",
            "        \"non_linearity\": \"relu\",\n",
            "        \"original_ln_after\": true,\n",
            "        \"original_ln_before\": true,\n",
            "        \"output_adapter\": true,\n",
            "        \"phm_bias\": true,\n",
            "        \"phm_c_init\": \"normal\",\n",
            "        \"phm_dim\": 4,\n",
            "        \"phm_init_range\": 0.0001,\n",
            "        \"phm_layer\": false,\n",
            "        \"phm_rank\": 1,\n",
            "        \"reduction_factor\": 2,\n",
            "        \"residual_before_ln\": true,\n",
            "        \"scaling\": 1.0,\n",
            "        \"shared_W_phm\": false,\n",
            "        \"shared_phm_rule\": true\n",
            "      },\n",
            "      \"9076f36a74755ac4\": {\n",
            "        \"adapter_residual_before_ln\": false,\n",
            "        \"cross_adapter\": false,\n",
            "        \"factorized_phm_W\": true,\n",
            "        \"factorized_phm_rule\": false,\n",
            "        \"hypercomplex_nonlinearity\": \"glorot-uniform\",\n",
            "        \"init_weights\": \"bert\",\n",
            "        \"inv_adapter\": null,\n",
            "        \"inv_adapter_reduction_factor\": null,\n",
            "        \"is_parallel\": false,\n",
            "        \"learn_phm\": true,\n",
            "        \"leave_out\": [],\n",
            "        \"ln_after\": false,\n",
            "        \"ln_before\": false,\n",
            "        \"mh_adapter\": false,\n",
            "        \"non_linearity\": \"relu\",\n",
            "        \"original_ln_after\": true,\n",
            "        \"original_ln_before\": true,\n",
            "        \"output_adapter\": true,\n",
            "        \"phm_bias\": true,\n",
            "        \"phm_c_init\": \"normal\",\n",
            "        \"phm_dim\": 4,\n",
            "        \"phm_init_range\": 0.0001,\n",
            "        \"phm_layer\": false,\n",
            "        \"phm_rank\": 1,\n",
            "        \"reduction_factor\": 16,\n",
            "        \"residual_before_ln\": true,\n",
            "        \"scaling\": 1.0,\n",
            "        \"shared_W_phm\": false,\n",
            "        \"shared_phm_rule\": true\n",
            "      }\n",
            "    },\n",
            "    \"fusion_config_map\": {},\n",
            "    \"fusions\": {}\n",
            "  },\n",
            "  \"architectures\": [\n",
            "    \"XLMRobertaForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"xlm-roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250002\n",
            "}\n",
            "\n",
            "loading weights file ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained/pytorch_model.bin\n",
            "Some weights of the model checkpoint at ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained were not used when initializing XLMRobertaForQuestionAnswering: ['roberta.encoder.layer.6.output.adapters.en.adapter_down.0.bias', 'roberta.encoder.layer.0.output.adapters.hi.adapter_up.weight', 'roberta.encoder.layer.5.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.4.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.5.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.encoder.layer.1.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.encoder.layer.7.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.encoder.layer.3.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.encoder.layer.2.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.10.output.adapters.hi.adapter_down.0.weight', 'roberta.encoder.layer.3.output.adapters.en.adapter_down.0.weight', 'roberta.encoder.layer.7.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.invertible_adapters.en.G.0.weight', 'roberta.encoder.layer.7.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.encoder.layer.7.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.2.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.encoder.layer.6.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.invertible_adapters.hi.G.0.weight', 'roberta.encoder.layer.11.output.adapters.en.adapter_down.0.weight', 'roberta.encoder.layer.8.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.encoder.layer.1.output.adapters.hi.adapter_down.0.weight', 'roberta.invertible_adapters.en.F.2.bias', 'roberta.encoder.layer.2.output.adapters.hi.adapter_down.0.weight', 'roberta.encoder.layer.4.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.encoder.layer.2.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.0.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.encoder.layer.2.output.adapters.en.adapter_up.bias', 'roberta.encoder.layer.3.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.encoder.layer.4.output.adapters.en.adapter_down.0.weight', 'roberta.encoder.layer.3.output.adapters.en.adapter_down.0.bias', 'roberta.invertible_adapters.hi.F.2.bias', 'roberta.encoder.layer.3.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.2.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.0.output.adapters.hi.adapter_down.0.weight', 'roberta.encoder.layer.10.output.adapters.hi.adapter_up.weight', 'roberta.encoder.layer.7.output.adapters.en.adapter_down.0.weight', 'roberta.invertible_adapters.en.F.0.weight', 'roberta.encoder.layer.3.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.5.output.adapters.hi.adapter_up.bias', 'roberta.encoder.layer.1.output.adapters.hi.adapter_up.bias', 'roberta.encoder.layer.6.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.invertible_adapters.hi.F.0.bias', 'roberta.encoder.layer.4.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.invertible_adapters.en.G.0.bias', 'roberta.encoder.layer.7.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.9.output.adapters.hi.adapter_down.0.weight', 'roberta.encoder.layer.0.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.encoder.layer.9.output.adapters.en.adapter_up.bias', 'roberta.encoder.layer.9.output.adapters.hi.adapter_up.weight', 'roberta.encoder.layer.4.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.8.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.1.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.1.output.adapters.en.adapter_down.0.weight', 'roberta.encoder.layer.8.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.encoder.layer.6.output.adapters.hi.adapter_up.bias', 'roberta.encoder.layer.10.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.2.output.adapters.hi.adapter_up.bias', 'roberta.encoder.layer.1.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.11.output.adapters.en.adapter_down.0.bias', 'roberta.encoder.layer.5.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.encoder.layer.11.output.adapters.hi.adapter_up.bias', 'roberta.encoder.layer.4.output.adapters.hi.adapter_down.0.weight', 'roberta.encoder.layer.5.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.4.output.adapters.en.adapter_up.bias', 'roberta.encoder.layer.6.output.adapters.hi.adapter_down.0.weight', 'roberta.encoder.layer.6.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.3.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.encoder.layer.10.output.adapters.en.adapter_down.0.bias', 'roberta.encoder.layer.7.output.adapters.en.adapter_up.bias', 'roberta.encoder.layer.0.output.adapters.en.adapter_up.bias', 'roberta.encoder.layer.7.output.adapters.en.adapter_down.0.bias', 'roberta.encoder.layer.6.output.adapters.hi.adapter_up.weight', 'roberta.encoder.layer.9.output.adapters.en.adapter_down.0.weight', 'roberta.encoder.layer.8.output.adapters.hi.adapter_up.weight', 'roberta.encoder.layer.5.output.adapters.en.adapter_up.bias', 'roberta.encoder.layer.11.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.3.output.adapters.hi.adapter_up.bias', 'roberta.encoder.layer.3.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.4.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.encoder.layer.8.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.encoder.layer.10.output.adapters.en.adapter_up.bias', 'roberta.encoder.layer.5.output.adapters.hi.adapter_down.0.weight', 'roberta.encoder.layer.9.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.6.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.10.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.invertible_adapters.hi.F.0.weight', 'roberta.encoder.layer.9.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.encoder.layer.9.output.adapters.en.adapter_down.0.bias', 'roberta.invertible_adapters.hi.G.0.bias', 'roberta.invertible_adapters.en.F.0.bias', 'roberta.encoder.layer.3.output.adapters.en.adapter_up.bias', 'roberta.invertible_adapters.en.F.2.weight', 'roberta.encoder.layer.9.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.0.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.5.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.5.output.adapters.en.adapter_down.0.bias', 'roberta.encoder.layer.8.output.adapters.hi.adapter_up.bias', 'roberta.encoder.layer.6.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.encoder.layer.1.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.encoder.layer.0.output.adapters.en.adapter_down.0.bias', 'roberta.encoder.layer.11.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.2.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.encoder.layer.6.output.adapters.en.adapter_up.bias', 'roberta.encoder.layer.7.output.adapters.hi.adapter_up.weight', 'roberta.encoder.layer.9.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.encoder.layer.3.output.adapters.hi.adapter_down.0.weight', 'roberta.encoder.layer.8.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.6.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.11.output.adapters.hi.adapter_up.weight', 'roberta.encoder.layer.7.output.adapters.hi.adapter_up.bias', 'roberta.invertible_adapters.hi.G.2.weight', 'roberta.encoder.layer.4.output.adapters.hi.adapter_up.bias', 'roberta.encoder.layer.1.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.4.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.0.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.encoder.layer.7.output.adapters.hi.adapter_down.0.weight', 'roberta.encoder.layer.0.output.adapters.hi.adapter_up.bias', 'roberta.encoder.layer.7.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.9.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.encoder.layer.5.output.adapters.hi.adapter_up.weight', 'roberta.invertible_adapters.en.G.2.weight', 'roberta.invertible_adapters.hi.F.2.weight', 'roberta.encoder.layer.8.output.adapters.en.adapter_up.bias', 'roberta.encoder.layer.1.output.adapters.hi.adapter_up.weight', 'roberta.encoder.layer.2.output.adapters.en.adapter_down.0.weight', 'roberta.encoder.layer.2.output.adapters.en.adapter_down.0.bias', 'roberta.encoder.layer.5.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.encoder.layer.10.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.encoder.layer.10.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.encoder.layer.8.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.4.output.adapters.en.adapter_down.0.bias', 'roberta.encoder.layer.8.output.adapters.en.adapter_down.0.bias', 'roberta.encoder.layer.0.output.adapters.en.adapter_down.0.weight', 'roberta.encoder.layer.11.output.adapters.en.adapter_up.bias', 'roberta.encoder.layer.3.output.adapters.hi.adapter_up.weight', 'roberta.encoder.layer.6.output.adapters.en.adapter_down.0.weight', 'roberta.encoder.layer.2.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.encoder.layer.11.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.10.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.10.output.adapters.hi.adapter_up.bias', 'roberta.encoder.layer.8.output.adapters.hi.adapter_down.0.weight', 'roberta.invertible_adapters.hi.G.2.bias', 'roberta.encoder.layer.2.output.adapters.hi.adapter_up.weight', 'roberta.invertible_adapters.en.G.2.bias', 'roberta.encoder.layer.1.output.adapters.en.adapter_up.bias', 'roberta.encoder.layer.4.output.adapters.hi.adapter_up.weight', 'roberta.encoder.layer.1.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.encoder.layer.5.output.adapters.en.adapter_down.0.weight', 'roberta.encoder.layer.11.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias', 'roberta.encoder.layer.1.output.adapters.en.adapter_down.0.bias', 'roberta.encoder.layer.11.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight', 'roberta.encoder.layer.11.output.adapters.hi.adapter_down.0.weight', 'roberta.encoder.layer.0.output.adapters.hi.adapter_down.0.bias', 'roberta.encoder.layer.11.output.adapters.pfeiffer_xlm_base.adapter_up.weight', 'roberta.encoder.layer.8.output.adapters.en.adapter_down.0.weight', 'roberta.encoder.layer.10.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.9.output.adapters.pfeiffer_xlm_base.adapter_up.bias', 'roberta.encoder.layer.0.output.adapters.en.adapter_up.weight', 'roberta.encoder.layer.10.output.adapters.en.adapter_down.0.weight', 'roberta.encoder.layer.9.output.adapters.hi.adapter_up.bias']\n",
            "- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of XLMRobertaForQuestionAnswering were initialized from the model checkpoint at ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForQuestionAnswering for predictions without further training.\n",
            "Loading module configuration from ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained/en/adapter_config.json\n",
            "Overwriting existing adapter 'en'.\n",
            "Loading module weights from ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained/en/pytorch_adapter.bin\n",
            "Some weights of the state_dict could not be loaded into model: roberta.invertible_adapters.en.F.0.weight, roberta.invertible_adapters.en.F.0.bias, roberta.invertible_adapters.en.F.2.weight, roberta.invertible_adapters.en.F.2.bias, roberta.invertible_adapters.en.G.0.weight, roberta.invertible_adapters.en.G.0.bias, roberta.invertible_adapters.en.G.2.weight, roberta.invertible_adapters.en.G.2.bias, roberta.encoder.layer.0.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.0.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.0.output.adapters.en.adapter_up.weight, roberta.encoder.layer.0.output.adapters.en.adapter_up.bias, roberta.encoder.layer.1.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.1.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.1.output.adapters.en.adapter_up.weight, roberta.encoder.layer.1.output.adapters.en.adapter_up.bias, roberta.encoder.layer.2.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.2.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.2.output.adapters.en.adapter_up.weight, roberta.encoder.layer.2.output.adapters.en.adapter_up.bias, roberta.encoder.layer.3.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.3.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.3.output.adapters.en.adapter_up.weight, roberta.encoder.layer.3.output.adapters.en.adapter_up.bias, roberta.encoder.layer.4.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.4.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.4.output.adapters.en.adapter_up.weight, roberta.encoder.layer.4.output.adapters.en.adapter_up.bias, roberta.encoder.layer.5.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.5.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.5.output.adapters.en.adapter_up.weight, roberta.encoder.layer.5.output.adapters.en.adapter_up.bias, roberta.encoder.layer.6.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.6.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.6.output.adapters.en.adapter_up.weight, roberta.encoder.layer.6.output.adapters.en.adapter_up.bias, roberta.encoder.layer.7.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.7.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.7.output.adapters.en.adapter_up.weight, roberta.encoder.layer.7.output.adapters.en.adapter_up.bias, roberta.encoder.layer.8.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.8.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.8.output.adapters.en.adapter_up.weight, roberta.encoder.layer.8.output.adapters.en.adapter_up.bias, roberta.encoder.layer.9.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.9.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.9.output.adapters.en.adapter_up.weight, roberta.encoder.layer.9.output.adapters.en.adapter_up.bias, roberta.encoder.layer.10.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.10.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.10.output.adapters.en.adapter_up.weight, roberta.encoder.layer.10.output.adapters.en.adapter_up.bias, roberta.encoder.layer.11.output.adapters.en.adapter_down.0.weight, roberta.encoder.layer.11.output.adapters.en.adapter_down.0.bias, roberta.encoder.layer.11.output.adapters.en.adapter_up.weight, roberta.encoder.layer.11.output.adapters.en.adapter_up.bias\n",
            "Loading module configuration from ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained/en/head_config.json\n",
            "Loading module weights from ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained/en/pytorch_model_head.bin\n",
            "Loading module configuration from ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained/hi/adapter_config.json\n",
            "Overwriting existing adapter 'hi'.\n",
            "Loading module weights from ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained/hi/pytorch_adapter.bin\n",
            "Some weights of the state_dict could not be loaded into model: roberta.invertible_adapters.hi.F.0.weight, roberta.invertible_adapters.hi.F.0.bias, roberta.invertible_adapters.hi.F.2.weight, roberta.invertible_adapters.hi.F.2.bias, roberta.invertible_adapters.hi.G.0.weight, roberta.invertible_adapters.hi.G.0.bias, roberta.invertible_adapters.hi.G.2.weight, roberta.invertible_adapters.hi.G.2.bias, roberta.encoder.layer.0.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.0.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.0.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.0.output.adapters.hi.adapter_up.bias, roberta.encoder.layer.1.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.1.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.1.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.1.output.adapters.hi.adapter_up.bias, roberta.encoder.layer.2.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.2.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.2.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.2.output.adapters.hi.adapter_up.bias, roberta.encoder.layer.3.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.3.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.3.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.3.output.adapters.hi.adapter_up.bias, roberta.encoder.layer.4.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.4.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.4.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.4.output.adapters.hi.adapter_up.bias, roberta.encoder.layer.5.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.5.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.5.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.5.output.adapters.hi.adapter_up.bias, roberta.encoder.layer.6.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.6.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.6.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.6.output.adapters.hi.adapter_up.bias, roberta.encoder.layer.7.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.7.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.7.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.7.output.adapters.hi.adapter_up.bias, roberta.encoder.layer.8.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.8.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.8.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.8.output.adapters.hi.adapter_up.bias, roberta.encoder.layer.9.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.9.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.9.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.9.output.adapters.hi.adapter_up.bias, roberta.encoder.layer.10.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.10.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.10.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.10.output.adapters.hi.adapter_up.bias, roberta.encoder.layer.11.output.adapters.hi.adapter_down.0.weight, roberta.encoder.layer.11.output.adapters.hi.adapter_down.0.bias, roberta.encoder.layer.11.output.adapters.hi.adapter_up.weight, roberta.encoder.layer.11.output.adapters.hi.adapter_up.bias\n",
            "Loading module configuration from ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained/hi/head_config.json\n",
            "Loading module weights from ./drive/MyDrive/Colab Files/models/hi-adapter-en-trained/hi/pytorch_model_head.bin\n",
            "Loading module configuration from /root/.cache/huggingface/hub/AdapterHub--roberta-base-pf-squad.main.f1507c5b9c07db12729b02f481ffb0ab434c042f/adapter_config.json\n",
            "Overwriting existing adapter 'pfeiffer_xlm_base'.\n",
            "Loading module weights from /root/.cache/huggingface/hub/AdapterHub--roberta-base-pf-squad.main.f1507c5b9c07db12729b02f481ffb0ab434c042f/pytorch_adapter.bin\n",
            "Some weights of the state_dict could not be loaded into model: roberta.encoder.layer.0.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.0.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.0.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.0.output.adapters.pfeiffer_xlm_base.adapter_up.bias, roberta.encoder.layer.1.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.1.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.1.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.1.output.adapters.pfeiffer_xlm_base.adapter_up.bias, roberta.encoder.layer.2.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.2.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.2.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.2.output.adapters.pfeiffer_xlm_base.adapter_up.bias, roberta.encoder.layer.3.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.3.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.3.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.3.output.adapters.pfeiffer_xlm_base.adapter_up.bias, roberta.encoder.layer.4.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.4.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.4.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.4.output.adapters.pfeiffer_xlm_base.adapter_up.bias, roberta.encoder.layer.5.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.5.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.5.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.5.output.adapters.pfeiffer_xlm_base.adapter_up.bias, roberta.encoder.layer.6.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.6.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.6.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.6.output.adapters.pfeiffer_xlm_base.adapter_up.bias, roberta.encoder.layer.7.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.7.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.7.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.7.output.adapters.pfeiffer_xlm_base.adapter_up.bias, roberta.encoder.layer.8.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.8.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.8.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.8.output.adapters.pfeiffer_xlm_base.adapter_up.bias, roberta.encoder.layer.9.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.9.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.9.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.9.output.adapters.pfeiffer_xlm_base.adapter_up.bias, roberta.encoder.layer.10.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.10.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.10.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.10.output.adapters.pfeiffer_xlm_base.adapter_up.bias, roberta.encoder.layer.11.output.adapters.pfeiffer_xlm_base.adapter_down.0.weight, roberta.encoder.layer.11.output.adapters.pfeiffer_xlm_base.adapter_down.0.bias, roberta.encoder.layer.11.output.adapters.pfeiffer_xlm_base.adapter_up.weight, roberta.encoder.layer.11.output.adapters.pfeiffer_xlm_base.adapter_up.bias\n",
            "Loading module configuration from /root/.cache/huggingface/hub/AdapterHub--roberta-base-pf-squad.main.f1507c5b9c07db12729b02f481ffb0ab434c042f/head_config.json\n",
            "Model class 'RobertaModelWithHeads' of found prediction head does not match current model class.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n"
      ],
      "metadata": {
        "id": "0C1lajPheXk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:09:37.676204Z",
          "iopub.execute_input": "2022-05-20T16:09:37.678348Z",
          "iopub.status.idle": "2022-05-20T16:09:37.685529Z",
          "shell.execute_reply.started": "2022-05-20T16:09:37.678292Z",
          "shell.execute_reply": "2022-05-20T16:09:37.684780Z"
        },
        "trusted": true,
        "id": "F8-FGmz_eXk-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    f\"./{language}-adapter-{batch_size}\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy= \"epoch\",\n",
        "    learning_rate = 3e-5,\n",
        "    warmup_ratio = 0.1,\n",
        "    gradient_accumulation_steps = 8,\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    seed=42,\n",
        "    fp16=True,\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:09:37.687014Z",
          "iopub.execute_input": "2022-05-20T16:09:37.687505Z",
          "iopub.status.idle": "2022-05-20T16:09:37.787874Z",
          "shell.execute_reply.started": "2022-05-20T16:09:37.687470Z",
          "shell.execute_reply": "2022-05-20T16:09:37.787050Z"
        },
        "trusted": true,
        "id": "kSP-SgqKeXk-",
        "outputId": "f6b10a6d-994b-432d-db4a-43c81b75600b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = default_data_collator"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:09:37.792589Z",
          "iopub.execute_input": "2022-05-20T16:09:37.794834Z",
          "iopub.status.idle": "2022-05-20T16:09:37.803595Z",
          "shell.execute_reply.started": "2022-05-20T16:09:37.794787Z",
          "shell.execute_reply": "2022-05-20T16:09:37.801419Z"
        },
        "trusted": true,
        "id": "WjMRMqGteXk-"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=squad_hi[\"train\"],\n",
        "    eval_dataset=squad_hi[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:09:37.805173Z",
          "iopub.execute_input": "2022-05-20T16:09:37.805604Z",
          "iopub.status.idle": "2022-05-20T16:09:42.407830Z",
          "shell.execute_reply.started": "2022-05-20T16:09:37.805565Z",
          "shell.execute_reply": "2022-05-20T16:09:42.407079Z"
        },
        "trusted": true,
        "id": "CgDI84y_eXk_",
        "outputId": "b5b8d5ae-a2bc-47eb-ba52-7879d4fe8bd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/./hi-adapter-32 is already a clone of https://huggingface.co/subhasisj/hi-adapter-32. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "Using amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T16:09:42.409246Z",
          "iopub.execute_input": "2022-05-20T16:09:42.409493Z",
          "iopub.status.idle": "2022-05-20T19:59:49.061678Z",
          "shell.execute_reply.started": "2022-05-20T16:09:42.409458Z",
          "shell.execute_reply": "2022-05-20T19:59:49.061010Z"
        },
        "trusted": true,
        "id": "6yluInhCeXk_",
        "outputId": "df021939-5a23-4d60-b858-5f3c024d6819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 91554\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
            "  Gradient Accumulation steps = 8\n",
            "  Total optimization steps = 1785\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='196' max='1785' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 196/1785 11:22 < 1:33:07, 0.28 it/s, Epoch 0.55/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T20:12:18.111102Z",
          "iopub.execute_input": "2022-05-20T20:12:18.111681Z",
          "iopub.status.idle": "2022-05-20T20:12:18.133597Z",
          "shell.execute_reply.started": "2022-05-20T20:12:18.111646Z",
          "shell.execute_reply": "2022-05-20T20:12:18.132688Z"
        },
        "trusted": true,
        "id": "ePkQJyQZeXk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.save_model(f\"./{language}-adapter-{batch_size}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T19:59:49.083698Z",
          "iopub.execute_input": "2022-05-20T19:59:49.083954Z",
          "iopub.status.idle": "2022-05-20T19:59:53.280627Z",
          "shell.execute_reply.started": "2022-05-20T19:59:49.083918Z",
          "shell.execute_reply": "2022-05-20T19:59:53.279861Z"
        },
        "trusted": true,
        "id": "oduXYyFaeXk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_adapter('./hi-adapter-16/runs',\"pfeiffer_xlm_base\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T19:59:53.281982Z",
          "iopub.execute_input": "2022-05-20T19:59:53.282257Z",
          "iopub.status.idle": "2022-05-20T19:59:53.325496Z",
          "shell.execute_reply.started": "2022-05-20T19:59:53.282222Z",
          "shell.execute_reply": "2022-05-20T19:59:53.324830Z"
        },
        "trusted": true,
        "id": "zC0mdX4yeXk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.makedirs('./hi-adapter-16/all')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T19:59:53.327985Z",
          "iopub.execute_input": "2022-05-20T19:59:53.328211Z",
          "iopub.status.idle": "2022-05-20T19:59:54.465769Z",
          "shell.execute_reply.started": "2022-05-20T19:59:53.328181Z",
          "shell.execute_reply": "2022-05-20T19:59:54.465113Z"
        },
        "trusted": true,
        "id": "31sFtkGWeXlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_adapter('./hi-adapter-16/en-adapter',\"en\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T19:59:54.470729Z",
          "iopub.execute_input": "2022-05-20T19:59:54.470975Z",
          "iopub.status.idle": "2022-05-20T19:59:54.548605Z",
          "shell.execute_reply.started": "2022-05-20T19:59:54.470943Z",
          "shell.execute_reply": "2022-05-20T19:59:54.547758Z"
        },
        "trusted": true,
        "id": "ItaWyPVleXlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_all_adapters(f'./drive/MyDrive/Colab Files/models/{language}-adapter-en-trained/all')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T19:59:54.549828Z",
          "iopub.execute_input": "2022-05-20T19:59:54.551169Z",
          "iopub.status.idle": "2022-05-20T19:59:55.728758Z",
          "shell.execute_reply.started": "2022-05-20T19:59:54.551129Z",
          "shell.execute_reply": "2022-05-20T19:59:55.727848Z"
        },
        "trusted": true,
        "id": "WOWvc_ZxeXlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# wandb.init(mode=\"disabled\")\n",
        "# wandb.init(mode=\"offline\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T19:59:55.730259Z",
          "iopub.execute_input": "2022-05-20T19:59:55.730788Z",
          "iopub.status.idle": "2022-05-20T20:00:04.509633Z",
          "shell.execute_reply.started": "2022-05-20T19:59:55.730747Z",
          "shell.execute_reply": "2022-05-20T20:00:04.508870Z"
        },
        "trusted": true,
        "id": "lpn5fZpoeXlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r   hi-adapters-16.zip  /kaggle/working/hi-adapter-16/all"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T20:12:54.939772Z",
          "iopub.execute_input": "2022-05-20T20:12:54.940062Z",
          "iopub.status.idle": "2022-05-20T20:12:58.850212Z",
          "shell.execute_reply.started": "2022-05-20T20:12:54.940022Z",
          "shell.execute_reply": "2022-05-20T20:12:58.849401Z"
        },
        "trusted": true,
        "id": "Hy0ejjP4eXlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.chdir(r'/kaggle/working')\n",
        "# from IPython.display import FileLink\n",
        "\n",
        "# FileLink(r'./hi-adapters-16.zip')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T20:13:11.453603Z",
          "iopub.execute_input": "2022-05-20T20:13:11.453894Z",
          "iopub.status.idle": "2022-05-20T20:13:11.463228Z",
          "shell.execute_reply.started": "2022-05-20T20:13:11.453863Z",
          "shell.execute_reply": "2022-05-20T20:13:11.462323Z"
        },
        "trusted": true,
        "id": "hO-vfpMZeXlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r   hi-model-checkpoint-16.zip  /kaggle/working/hi-adapter-16/checkpoint-3500"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T20:15:03.049601Z",
          "iopub.execute_input": "2022-05-20T20:15:03.049928Z",
          "iopub.status.idle": "2022-05-20T20:19:28.210428Z",
          "shell.execute_reply.started": "2022-05-20T20:15:03.049898Z",
          "shell.execute_reply": "2022-05-20T20:19:28.209584Z"
        },
        "trusted": true,
        "id": "_VTxDf7BeXlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FileLink(r'./hi-model-checkpoint-16.zip')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-20T20:20:46.553839Z",
          "iopub.execute_input": "2022-05-20T20:20:46.554140Z",
          "iopub.status.idle": "2022-05-20T20:20:46.562341Z",
          "shell.execute_reply.started": "2022-05-20T20:20:46.554108Z",
          "shell.execute_reply": "2022-05-20T20:20:46.561652Z"
        },
        "trusted": true,
        "id": "v5zAio3meXlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uZnJXDpHeXlB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}