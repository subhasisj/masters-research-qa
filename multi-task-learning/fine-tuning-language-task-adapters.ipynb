{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:21:08.457469Z","iopub.execute_input":"2022-05-20T11:21:08.457728Z","iopub.status.idle":"2022-05-20T11:21:09.153772Z","shell.execute_reply.started":"2022-05-20T11:21:08.457690Z","shell.execute_reply":"2022-05-20T11:21:09.152846Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install datasets adapter-transformers","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:01:44.810422Z","iopub.execute_input":"2022-05-20T16:01:44.811154Z","iopub.status.idle":"2022-05-20T16:02:02.448422Z","shell.execute_reply.started":"2022-05-20T16:01:44.811063Z","shell.execute_reply":"2022-05-20T16:02:02.447567Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade --force-reinstall pyarrow","metadata":{"execution":{"iopub.status.busy":"2022-05-20T11:20:57.265032Z","iopub.execute_input":"2022-05-20T11:20:57.265330Z","iopub.status.idle":"2022-05-20T11:21:00.815623Z","shell.execute_reply.started":"2022-05-20T11:20:57.265288Z","shell.execute_reply":"2022-05-20T11:21:00.814483Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict, load_dataset\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport json\nfrom transformers.adapters.composition import Fuse\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForQuestionAnswering,\n    AutoModelWithHeads,\n    Trainer,\n    TrainingArguments,\n    DataCollatorWithPadding,\n    default_data_collator,\n    PreTrainedTokenizerFast,\n    AutoAdapterModel,\n    AdapterConfig,\n    AutoModelForQuestionAnswering,\n)\nfrom transformers import AdapterConfig\nfrom transformers.adapters.composition import Stack\n\nwarnings.filterwarnings(\"ignore\")\nimport wandb\nwandb.init(mode=\"disabled\")\nwandb.init(mode=\"offline\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:03:59.647650Z","iopub.execute_input":"2022-05-20T16:03:59.647910Z","iopub.status.idle":"2022-05-20T16:04:05.414053Z","shell.execute_reply.started":"2022-05-20T16:03:59.647882Z","shell.execute_reply":"2022-05-20T16:04:05.413337Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"def squad_json_to_dataframe_train(input_file_path, record_path = ['data','paragraphs','qas','answers'],\n                           verbose = 1):\n    \"\"\"\n    input_file_path: path to the squad json file.\n    record_path: path to deepest level in json file default value is\n    ['data','paragraphs','qas','answers']\n    verbose: 0 to suppress it default is 1\n    \"\"\"\n    if verbose:\n        print(\"Reading the json file\")    \n    file = json.loads(open(input_file_path).read())\n    if verbose:\n        print(\"processing...\")\n    # parsing different level's in the json file\n    js = pd.io.json.json_normalize(file , record_path )\n    m = pd.io.json.json_normalize(file, record_path[:-1] )\n    r = pd.io.json.json_normalize(file,record_path[:-2])\n    \n    #combining it into single dataframe\n    idx = np.repeat(r['context'].values, r.qas.str.len())\n    ndx  = np.repeat(m['id'].values,m['answers'].str.len())\n    m['context'] = idx\n    js['q_idx'] = ndx\n    main = pd.concat([ m[['id','question','context']].set_index('id'),js.set_index('q_idx')],1,sort=False).reset_index()\n    main['c_id'] = main['context'].factorize()[0]\n    if verbose:\n        print(\"shape of the dataframe is {}\".format(main.shape))\n        print(\"Done\")\n    return main","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:04:20.989850Z","iopub.execute_input":"2022-05-20T16:04:20.990223Z","iopub.status.idle":"2022-05-20T16:04:21.009601Z","shell.execute_reply.started":"2022-05-20T16:04:20.990180Z","shell.execute_reply":"2022-05-20T16:04:21.008484Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# training data\nlanguage = 'hi'\ninput_file_path = f'../input/squadenhi/squad.translate.train.en-{language}.json'\nrecord_path = ['data','paragraphs','qas','answers']\ntrain = squad_json_to_dataframe_train(input_file_path=input_file_path,record_path=record_path,verbose=0)\n\ndef get_answers(x):\n    start = x[0]\n    text = x[1]\n    return {\n        'answer_start': [start],\n        'text': [text]\n    }\n\ntrain['answers'] = train[['answer_start', 'text']].apply(get_answers, axis=1)\npd.set_option('display.max_colwidth',None)\ntrain.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:04:21.146454Z","iopub.execute_input":"2022-05-20T16:04:21.146771Z","iopub.status.idle":"2022-05-20T16:04:39.573385Z","shell.execute_reply.started":"2022-05-20T16:04:21.146735Z","shell.execute_reply":"2022-05-20T16:04:39.572613Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Validation data\nlanguage = 'hi'\ninput_file_path = f'../input/squadenhi/squad.translate.dev.en-{language}.json'\nrecord_path = ['data','paragraphs','qas','answers']\ndev = squad_json_to_dataframe_train(input_file_path=input_file_path,record_path=record_path,verbose=0)\ndev['answers'] = dev[['answer_start', 'text']].apply(get_answers, axis=1)\npd.set_option('display.max_colwidth',None)\ndev.head(1)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:04:39.576546Z","iopub.execute_input":"2022-05-20T16:04:39.576946Z","iopub.status.idle":"2022-05-20T16:04:47.030775Z","shell.execute_reply.started":"2022-05-20T16:04:39.576913Z","shell.execute_reply":"2022-05-20T16:04:47.030079Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tds = Dataset.from_pandas(train.sample(100))\nvds = Dataset.from_pandas(dev.sample(100))\n\n\nsquad_hi = DatasetDict()\n\nsquad_hi['train'] = tds\nsquad_hi['validation'] = vds","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:04:47.032236Z","iopub.execute_input":"2022-05-20T16:04:47.032637Z","iopub.status.idle":"2022-05-20T16:04:47.107415Z","shell.execute_reply.started":"2022-05-20T16:04:47.032599Z","shell.execute_reply":"2022-05-20T16:04:47.106689Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"squad_hi","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:04:47.109307Z","iopub.execute_input":"2022-05-20T16:04:47.109566Z","iopub.status.idle":"2022-05-20T16:04:47.120074Z","shell.execute_reply.started":"2022-05-20T16:04:47.109521Z","shell.execute_reply":"2022-05-20T16:04:47.119312Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"squad_en = load_dataset(\"squad\")\nsquad_en","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:04:47.121309Z","iopub.execute_input":"2022-05-20T16:04:47.121977Z","iopub.status.idle":"2022-05-20T16:05:05.585099Z","shell.execute_reply.started":"2022-05-20T16:04:47.121940Z","shell.execute_reply":"2022-05-20T16:05:05.584357Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Create QA Features","metadata":{}},{"cell_type":"code","source":"\ntokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\nassert isinstance(tokenizer, PreTrainedTokenizerFast)\npad_on_right = tokenizer.padding_side == \"right\"","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:05:05.586519Z","iopub.execute_input":"2022-05-20T16:05:05.587055Z","iopub.status.idle":"2022-05-20T16:05:22.730261Z","shell.execute_reply.started":"2022-05-20T16:05:05.586995Z","shell.execute_reply":"2022-05-20T16:05:22.729049Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"max_length = 384 # The maximum length of a feature (question and context)\ndoc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.\ndef prepare_train_features(examples):\n    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n    # left whitespace\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n    # in one example possible giving several features when a context is long, each of those features having a\n    # context that overlaps a bit the context of the previous feature.\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # Since one example might give us several features if it has a long context, we need a map from a feature to\n    # its corresponding example. This key gives us just that.\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    # The offset mappings will give us a map from token to character position in the original context. This will\n    # help us compute the start_positions and end_positions.\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n\n    # Let's label those examples!\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        # We will label impossible answers with the index of the CLS token.\n        input_ids = tokenized_examples[\"input_ids\"][i]\n        cls_index = input_ids.index(tokenizer.cls_token_id)\n\n        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n        sequence_ids = tokenized_examples.sequence_ids(i)\n\n        # One example can give several spans, this is the index of the example containing this span of text.\n        sample_index = sample_mapping[i]\n        answers = examples[\"answers\"][sample_index]\n        # If no answers are given, set the cls_index as answer.\n        if len(answers[\"answer_start\"]) == 0:\n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n        else:\n            # Start/end character index of the answer in the text.\n            start_char = answers[\"answer_start\"][0]\n            end_char = start_char + len(answers[\"text\"][0])\n\n            # Start token index of the current span in the text.\n            token_start_index = 0\n            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n                token_start_index += 1\n\n            # End token index of the current span in the text.\n            token_end_index = len(input_ids) - 1\n            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n                token_end_index -= 1\n\n            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n                tokenized_examples[\"start_positions\"].append(cls_index)\n                tokenized_examples[\"end_positions\"].append(cls_index)\n            else:\n                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n                # Note: we could go after the last offset if the answer is the last word (edge case).\n                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                    token_start_index += 1\n                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n                while offsets[token_end_index][1] >= end_char:\n                    token_end_index -= 1\n                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n\n    return tokenized_examples\n\ndef prepare_validation_features(examples):\n    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n    # left whitespace\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n    # in one example possible giving several features when a context is long, each of those features having a\n    # context that overlaps a bit the context of the previous feature.\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # Since one example might give us several features if it has a long context, we need a map from a feature to\n    # its corresponding example. This key gives us just that.\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n\n    # We keep the example_id that gave us this feature and we will store the offset mappings.\n    tokenized_examples[\"example_id\"] = []\n\n    for i in range(len(tokenized_examples[\"input_ids\"])):\n        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        context_index = 1 if pad_on_right else 0\n\n        # One example can give several spans, this is the index of the example containing this span of text.\n        sample_index = sample_mapping[i]\n        tokenized_examples[\"example_id\"].append(examples[\"index\"][sample_index])\n\n        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n        # position is part of the context or not.\n        tokenized_examples[\"offset_mapping\"][i] = [\n            (o if sequence_ids[k] == context_index else None)\n            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n        ]\n\n    return tokenized_examples","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:05:22.735493Z","iopub.execute_input":"2022-05-20T16:05:22.735966Z","iopub.status.idle":"2022-05-20T16:05:22.776834Z","shell.execute_reply.started":"2022-05-20T16:05:22.735921Z","shell.execute_reply":"2022-05-20T16:05:22.775967Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# squad = squad.map(\n#     prepare_train_features, batched=True, remove_columns=squad[\"train\"].column_names\n# )\n\nsquad_en = squad_en.map(\n    prepare_train_features, batched=True, remove_columns=squad_en[\"train\"].column_names\n)\n\nsquad_hi = squad_hi.map(\n    prepare_train_features, batched=True, remove_columns=squad_hi[\"train\"].column_names\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:05:22.782556Z","iopub.execute_input":"2022-05-20T16:05:22.785217Z","iopub.status.idle":"2022-05-20T16:07:04.543165Z","shell.execute_reply.started":"2022-05-20T16:05:22.785179Z","shell.execute_reply":"2022-05-20T16:07:04.542473Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Load Model and Adapters\n\n### Enable EN only for training","metadata":{}},{"cell_type":"code","source":"model = AutoModelForQuestionAnswering.from_pretrained('xlm-roberta-base')\nconfig = AdapterConfig.load(\"pfeiffer\",non_linearity=\"relu\", reduction_factor=2)\nadapter_name_1 = model.load_adapter(\"en/wiki@ukp\", config=config,model_name='xlm-roberta-base')\nadapter_name_2 = model.load_adapter(\"hi/wiki@ukp\",config=config)\ntask_adapter = model.load_adapter(\"AdapterHub/roberta-base-pf-squad\", source=\"hf\",load_as = 'pfeiffer_xlm_base')\nmodel.set_active_adapters(adapter_name_1,task_adapter)\nmodel.train_adapter('pfeiffer_xlm_base')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:07:04.544532Z","iopub.execute_input":"2022-05-20T16:07:04.544802Z","iopub.status.idle":"2022-05-20T16:09:37.670591Z","shell.execute_reply.started":"2022-05-20T16:07:04.544766Z","shell.execute_reply":"2022-05-20T16:09:37.669853Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Training\n\n","metadata":{}},{"cell_type":"code","source":"batch_size = 16","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:09:37.676204Z","iopub.execute_input":"2022-05-20T16:09:37.678348Z","iopub.status.idle":"2022-05-20T16:09:37.685529Z","shell.execute_reply.started":"2022-05-20T16:09:37.678292Z","shell.execute_reply":"2022-05-20T16:09:37.684780Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments(\n    f\"./{language}-adapter-{batch_size}\",\n    evaluation_strategy = \"epoch\",\n    save_strategy= \"epoch\",\n    learning_rate = 3e-5,\n    warmup_ratio = 0.1,\n    gradient_accumulation_steps = 8,\n    num_train_epochs = 5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    seed=42,\n    fp16=True,\n    overwrite_output_dir=True,\n    save_total_limit=1,\n    load_best_model_at_end=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:09:37.687014Z","iopub.execute_input":"2022-05-20T16:09:37.687505Z","iopub.status.idle":"2022-05-20T16:09:37.787874Z","shell.execute_reply.started":"2022-05-20T16:09:37.687470Z","shell.execute_reply":"2022-05-20T16:09:37.787050Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data_collator = default_data_collator","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:09:37.792589Z","iopub.execute_input":"2022-05-20T16:09:37.794834Z","iopub.status.idle":"2022-05-20T16:09:37.803595Z","shell.execute_reply.started":"2022-05-20T16:09:37.794787Z","shell.execute_reply":"2022-05-20T16:09:37.801419Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=squad_en[\"train\"],\n    eval_dataset=squad_en[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:09:37.805173Z","iopub.execute_input":"2022-05-20T16:09:37.805604Z","iopub.status.idle":"2022-05-20T16:09:42.407830Z","shell.execute_reply.started":"2022-05-20T16:09:37.805565Z","shell.execute_reply":"2022-05-20T16:09:42.407079Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-05-20T16:09:42.409246Z","iopub.execute_input":"2022-05-20T16:09:42.409493Z","iopub.status.idle":"2022-05-20T19:59:49.061678Z","shell.execute_reply.started":"2022-05-20T16:09:42.409458Z","shell.execute_reply":"2022-05-20T19:59:49.061010Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"trainer.model","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:12:18.111102Z","iopub.execute_input":"2022-05-20T20:12:18.111681Z","iopub.status.idle":"2022-05-20T20:12:18.133597Z","shell.execute_reply.started":"2022-05-20T20:12:18.111646Z","shell.execute_reply":"2022-05-20T20:12:18.132688Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"trainer.save_model(f\"./{language}-adapter-{batch_size}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T19:59:49.083698Z","iopub.execute_input":"2022-05-20T19:59:49.083954Z","iopub.status.idle":"2022-05-20T19:59:53.280627Z","shell.execute_reply.started":"2022-05-20T19:59:49.083918Z","shell.execute_reply":"2022-05-20T19:59:53.279861Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model.save_adapter('./hi-adapter-16/runs',\"pfeiffer_xlm_base\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T19:59:53.281982Z","iopub.execute_input":"2022-05-20T19:59:53.282257Z","iopub.status.idle":"2022-05-20T19:59:53.325496Z","shell.execute_reply.started":"2022-05-20T19:59:53.282222Z","shell.execute_reply":"2022-05-20T19:59:53.324830Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import os\nos.makedirs('./hi-adapter-16/all')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T19:59:53.327985Z","iopub.execute_input":"2022-05-20T19:59:53.328211Z","iopub.status.idle":"2022-05-20T19:59:54.465769Z","shell.execute_reply.started":"2022-05-20T19:59:53.328181Z","shell.execute_reply":"2022-05-20T19:59:54.465113Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model.save_adapter('./hi-adapter-16/en-adapter',\"en\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T19:59:54.470729Z","iopub.execute_input":"2022-05-20T19:59:54.470975Z","iopub.status.idle":"2022-05-20T19:59:54.548605Z","shell.execute_reply.started":"2022-05-20T19:59:54.470943Z","shell.execute_reply":"2022-05-20T19:59:54.547758Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.save_all_adapters(\"./hi-adapter-16/all\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T19:59:54.549828Z","iopub.execute_input":"2022-05-20T19:59:54.551169Z","iopub.status.idle":"2022-05-20T19:59:55.728758Z","shell.execute_reply.started":"2022-05-20T19:59:54.551129Z","shell.execute_reply":"2022-05-20T19:59:55.727848Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"%%capture\nwandb.init(mode=\"disabled\")\nwandb.init(mode=\"offline\")","metadata":{"execution":{"iopub.status.busy":"2022-05-20T19:59:55.730259Z","iopub.execute_input":"2022-05-20T19:59:55.730788Z","iopub.status.idle":"2022-05-20T20:00:04.509633Z","shell.execute_reply.started":"2022-05-20T19:59:55.730747Z","shell.execute_reply":"2022-05-20T20:00:04.508870Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"!zip -r   hi-adapters-16.zip  /kaggle/working/hi-adapter-16/all","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:12:54.939772Z","iopub.execute_input":"2022-05-20T20:12:54.940062Z","iopub.status.idle":"2022-05-20T20:12:58.850212Z","shell.execute_reply.started":"2022-05-20T20:12:54.940022Z","shell.execute_reply":"2022-05-20T20:12:58.849401Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\n\nFileLink(r'./hi-adapters-16.zip')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:13:11.453603Z","iopub.execute_input":"2022-05-20T20:13:11.453894Z","iopub.status.idle":"2022-05-20T20:13:11.463228Z","shell.execute_reply.started":"2022-05-20T20:13:11.453863Z","shell.execute_reply":"2022-05-20T20:13:11.462323Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"!zip -r   hi-model-checkpoint-16.zip  /kaggle/working/hi-adapter-16/checkpoint-3500","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:15:03.049601Z","iopub.execute_input":"2022-05-20T20:15:03.049928Z","iopub.status.idle":"2022-05-20T20:19:28.210428Z","shell.execute_reply.started":"2022-05-20T20:15:03.049898Z","shell.execute_reply":"2022-05-20T20:19:28.209584Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"FileLink(r'./hi-model-checkpoint-16.zip')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T20:20:46.553839Z","iopub.execute_input":"2022-05-20T20:20:46.554140Z","iopub.status.idle":"2022-05-20T20:20:46.562341Z","shell.execute_reply.started":"2022-05-20T20:20:46.554108Z","shell.execute_reply":"2022-05-20T20:20:46.561652Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}