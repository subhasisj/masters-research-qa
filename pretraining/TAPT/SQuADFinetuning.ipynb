{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"R5oS5LUAoEu_","outputId":"9f09bc6c-0f7d-4a7b-e22d-e99b38e06026","execution":{"iopub.status.busy":"2022-05-12T12:37:25.473058Z","iopub.execute_input":"2022-05-12T12:37:25.473445Z","iopub.status.idle":"2022-05-12T12:37:26.195491Z","shell.execute_reply.started":"2022-05-12T12:37:25.473377Z","shell.execute_reply":"2022-05-12T12:37:26.194490Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Thu May 12 12:37:26 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   40C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers==4.18.0\n!pip install -U datasets","metadata":{"id":"IEdqAaxwofJr","outputId":"d63c4259-e117-4859-9698-d5628fece6a8","execution":{"iopub.status.busy":"2022-05-12T12:37:26.206167Z","iopub.execute_input":"2022-05-12T12:37:26.206380Z","iopub.status.idle":"2022-05-12T12:37:46.972972Z","shell.execute_reply.started":"2022-05-12T12:37:26.206351Z","shell.execute_reply":"2022-05-12T12:37:46.972097Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers==4.18.0 in /opt/conda/lib/python3.7/site-packages (4.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.18.0) (1.21.6)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.18.0) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.18.0) (2021.11.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.18.0) (2.27.1)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.18.0) (0.0.49)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.18.0) (4.63.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.18.0) (3.6.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.18.0) (0.12.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.18.0) (4.11.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.18.0) (0.5.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.18.0) (21.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers==4.18.0) (3.0.7)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.18.0) (3.7.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.18.0) (1.26.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.18.0) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.18.0) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.18.0) (2.0.12)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.18.0) (8.0.4)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.18.0) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting datasets\n  Downloading datasets-2.2.1-py3-none-any.whl (342 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.2/342.2 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.27.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nCollecting responses<0.19\n  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.63.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.5.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (8.0.0)\nCollecting xxhash\n  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.12)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.7.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\nInstalling collected packages: xxhash, responses, datasets\nSuccessfully installed datasets-2.2.1 responses-0.18.0 xxhash-3.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"pip install --upgrade --force-reinstall pyarrow","metadata":{"id":"pK5rPlaUonEv","outputId":"04404c00-9906-47a8-84f2-88d8ae0c3486","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json # to read json\nfrom datasets import load_dataset,Dataset,DatasetDict\nimport warnings # to ignore warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"h9Ts9sVGoDwC","execution":{"iopub.status.busy":"2022-05-12T12:37:46.976702Z","iopub.execute_input":"2022-05-12T12:37:46.976933Z","iopub.status.idle":"2022-05-12T12:37:53.746344Z","shell.execute_reply.started":"2022-05-12T12:37:46.976905Z","shell.execute_reply":"2022-05-12T12:37:53.745619Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"id":"fpVIvGgkoDwF","outputId":"827f7a41-15ff-49c1-850c-47cca044f38a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def squad_json_to_dataframe_train(input_file_path, record_path = ['data','paragraphs','qas','answers'],\n                           verbose = 1):\n    \"\"\"\n    input_file_path: path to the squad json file.\n    record_path: path to deepest level in json file default value is\n    ['data','paragraphs','qas','answers']\n    verbose: 0 to suppress it default is 1\n    \"\"\"\n    if verbose:\n        print(\"Reading the json file\")    \n    file = json.loads(open(input_file_path).read())\n    if verbose:\n        print(\"processing...\")\n    # parsing different level's in the json file\n    js = pd.io.json.json_normalize(file , record_path )\n    m = pd.io.json.json_normalize(file, record_path[:-1] )\n    r = pd.io.json.json_normalize(file,record_path[:-2])\n    \n    #combining it into single dataframe\n    idx = np.repeat(r['context'].values, r.qas.str.len())\n    ndx  = np.repeat(m['id'].values,m['answers'].str.len())\n    m['context'] = idx\n    js['q_idx'] = ndx\n    main = pd.concat([ m[['id','question','context']].set_index('id'),js.set_index('q_idx')],1,sort=False).reset_index()\n    main['c_id'] = main['context'].factorize()[0]\n    if verbose:\n        print(\"shape of the dataframe is {}\".format(main.shape))\n        print(\"Done\")\n    return main","metadata":{"id":"ZyyzwzuYoDwF","execution":{"iopub.status.busy":"2022-05-12T12:38:00.156504Z","iopub.execute_input":"2022-05-12T12:38:00.156780Z","iopub.status.idle":"2022-05-12T12:38:00.166905Z","shell.execute_reply.started":"2022-05-12T12:38:00.156750Z","shell.execute_reply":"2022-05-12T12:38:00.166071Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training data\nlanguage = 'hi'\ninput_file_path = f'../input/squadenhi/squad.translate.train.en-{language}.json'\nrecord_path = ['data','paragraphs','qas','answers']\ntrain = squad_json_to_dataframe_train(input_file_path=input_file_path,record_path=record_path,verbose=0)","metadata":{"id":"kuTEOcWBoDwG","execution":{"iopub.status.busy":"2022-05-12T12:38:01.404266Z","iopub.execute_input":"2022-05-12T12:38:01.404737Z","iopub.status.idle":"2022-05-12T12:38:19.038507Z","shell.execute_reply.started":"2022-05-12T12:38:01.404698Z","shell.execute_reply":"2022-05-12T12:38:19.037738Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"id":"uzU8CZaZoDwH","outputId":"2d8dc51f-36b7-4be0-f6cf-0d1869aac292","execution":{"iopub.status.busy":"2022-05-12T12:38:19.040258Z","iopub.execute_input":"2022-05-12T12:38:19.040507Z","iopub.status.idle":"2022-05-12T12:38:19.061164Z","shell.execute_reply.started":"2022-05-12T12:38:19.040472Z","shell.execute_reply":"2022-05-12T12:38:19.060502Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                      index  \\\n0  57283b4c3acd2414000df76d   \n1  5727dbb33acd2414000dee30   \n2  5733ec8ed058e614000b65f0   \n3  573405584776f41900661710   \n4  5726c05fdd62a815002e8f65   \n\n                                            question  \\\n0            जब लंदन यहूदी फोरम स्थापित किया गया था?   \n1  लुंडेनविक के एंग्लो-सैक्सन समझौते के पतन के लि...   \n2  मानवविज्ञानी आमतौर पर दुनिया को कैसे विभाजित क...   \n3  पुर्तगाल के पास किस क्षेत्र में लोहे और कोयले ...   \n4  ट्राइग्लिसराइड में कितने ग्लिसरॉल बैकबोन होते ...   \n\n                                             context  answer_start  \\\n0  उत्तरी लंदन में स्टैमफोर्ड हिल, स्टैनमोर, गोल्...           546   \n1  5 वीं शताब्दी की शुरुआत में रोमन शासन के पतन क...           522   \n2  सैद्धांतिक जोर से अपनी परियोजना को विभाजित करन...            96   \n3  पुर्तगाल एक महत्वपूर्ण यूरोपीय खनिज उत्पादक है...           411   \n4  आहार वसा के एक अणु में आमतौर पर कई फैटी एसिड (...           213   \n\n                                                text  c_id  \n0                                               2006     0  \n1              की गिरावट आई से दोहराया वाइकिंग हमलों     1  \n2  प्रासंगिक समय अवधि और भौगोलिक क्षेत्रों में वि...     2  \n3                                              उत्तर     3  \n4                                                 एक     4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer_start</th>\n      <th>text</th>\n      <th>c_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57283b4c3acd2414000df76d</td>\n      <td>जब लंदन यहूदी फोरम स्थापित किया गया था?</td>\n      <td>उत्तरी लंदन में स्टैमफोर्ड हिल, स्टैनमोर, गोल्...</td>\n      <td>546</td>\n      <td>2006</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5727dbb33acd2414000dee30</td>\n      <td>लुंडेनविक के एंग्लो-सैक्सन समझौते के पतन के लि...</td>\n      <td>5 वीं शताब्दी की शुरुआत में रोमन शासन के पतन क...</td>\n      <td>522</td>\n      <td>की गिरावट आई से दोहराया वाइकिंग हमलों</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5733ec8ed058e614000b65f0</td>\n      <td>मानवविज्ञानी आमतौर पर दुनिया को कैसे विभाजित क...</td>\n      <td>सैद्धांतिक जोर से अपनी परियोजना को विभाजित करन...</td>\n      <td>96</td>\n      <td>प्रासंगिक समय अवधि और भौगोलिक क्षेत्रों में वि...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>573405584776f41900661710</td>\n      <td>पुर्तगाल के पास किस क्षेत्र में लोहे और कोयले ...</td>\n      <td>पुर्तगाल एक महत्वपूर्ण यूरोपीय खनिज उत्पादक है...</td>\n      <td>411</td>\n      <td>उत्तर</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5726c05fdd62a815002e8f65</td>\n      <td>ट्राइग्लिसराइड में कितने ग्लिसरॉल बैकबोन होते ...</td>\n      <td>आहार वसा के एक अणु में आमतौर पर कई फैटी एसिड (...</td>\n      <td>213</td>\n      <td>एक</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def get_answers(x):\n    start = x[0]\n    text = x[1]\n    return {\n        'answer_start': [start],\n        'text': [text]\n    }\n\ntrain['answers'] = train[['answer_start', 'text']].apply(get_answers, axis=1)\npd.set_option('display.max_colwidth',None)\ntrain.head(1)","metadata":{"id":"KrDpmeTlqgap","outputId":"dc4d820b-0f8b-4014-cad5-4eb5e2b58591","execution":{"iopub.status.busy":"2022-05-12T12:38:19.063576Z","iopub.execute_input":"2022-05-12T12:38:19.064287Z","iopub.status.idle":"2022-05-12T12:38:20.209097Z","shell.execute_reply.started":"2022-05-12T12:38:19.064247Z","shell.execute_reply":"2022-05-12T12:38:20.208247Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                      index                                 question  \\\n0  57283b4c3acd2414000df76d  जब लंदन यहूदी फोरम स्थापित किया गया था?   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              context  \\\n0  उत्तरी लंदन में स्टैमफोर्ड हिल, स्टैनमोर, गोल्डर्स ग्रीन, फिंचली, हैम्पस्टेड, हेंडन और एडगवेयर में महत्वपूर्ण यहूदी समुदायों के साथ अधिकांश ब्रिटिश यहूदी लंदन में रहते हैं। लंदन शहर के Bevis मार्क्स आराधनालय लंदन के ऐतिहासिक Sephardic यहूदी समुदाय से सम्बद्ध है। यह यूरोप का एकमात्र ऐसा आराधनालय है जिसने 300 वर्षों से लगातार नियमित सेवाओं का आयोजन किया है। स्टैनमोर और कैनन्स पार्क सिनेगॉग की 1998 में पूरे यूरोप में किसी भी ऑर्थोडॉक्स आराधनालय की सबसे बड़ी सदस्यता है, 1998 में इलफ़र्ड सिनेगॉग (लंदन में भी) से आगे निकल गया। समुदाय ने जवाब में 2006 में लंदन यहूदी फोरम की स्थापना की। विकसित लंदन सरकार के बढ़ते महत्व के लिए।   \n\n   answer_start  text  c_id                                    answers  \n0           546  2006     0  {'answer_start': [546], 'text': ['2006']}  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer_start</th>\n      <th>text</th>\n      <th>c_id</th>\n      <th>answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57283b4c3acd2414000df76d</td>\n      <td>जब लंदन यहूदी फोरम स्थापित किया गया था?</td>\n      <td>उत्तरी लंदन में स्टैमफोर्ड हिल, स्टैनमोर, गोल्डर्स ग्रीन, फिंचली, हैम्पस्टेड, हेंडन और एडगवेयर में महत्वपूर्ण यहूदी समुदायों के साथ अधिकांश ब्रिटिश यहूदी लंदन में रहते हैं। लंदन शहर के Bevis मार्क्स आराधनालय लंदन के ऐतिहासिक Sephardic यहूदी समुदाय से सम्बद्ध है। यह यूरोप का एकमात्र ऐसा आराधनालय है जिसने 300 वर्षों से लगातार नियमित सेवाओं का आयोजन किया है। स्टैनमोर और कैनन्स पार्क सिनेगॉग की 1998 में पूरे यूरोप में किसी भी ऑर्थोडॉक्स आराधनालय की सबसे बड़ी सदस्यता है, 1998 में इलफ़र्ड सिनेगॉग (लंदन में भी) से आगे निकल गया। समुदाय ने जवाब में 2006 में लंदन यहूदी फोरम की स्थापना की। विकसित लंदन सरकार के बढ़ते महत्व के लिए।</td>\n      <td>546</td>\n      <td>2006</td>\n      <td>0</td>\n      <td>{'answer_start': [546], 'text': ['2006']}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Validation data\nlanguage = 'hi'\ninput_file_path = f'../input/squadenhi/squad.translate.dev.en-{language}.json'\nrecord_path = ['data','paragraphs','qas','answers']\ndev = squad_json_to_dataframe_train(input_file_path=input_file_path,record_path=record_path,verbose=0)\ndev['answers'] = dev[['answer_start', 'text']].apply(get_answers, axis=1)\npd.set_option('display.max_colwidth',None)\ndev.head(1)","metadata":{"id":"m35c0mGloDwI","outputId":"6a9c9c9f-e8fc-4bd3-bffe-1e15e410b87f","execution":{"iopub.status.busy":"2022-05-12T12:38:20.211312Z","iopub.execute_input":"2022-05-12T12:38:20.211587Z","iopub.status.idle":"2022-05-12T12:38:28.034507Z","shell.execute_reply.started":"2022-05-12T12:38:20.211550Z","shell.execute_reply":"2022-05-12T12:38:28.033790Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                      index                                   question  \\\n0  56e1c9bfe3433e1400423196  बहुपद समय में कमी क्या इसका एक उदाहरण है?   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 context  \\\n0  कमी की अवधारणा का उपयोग करके कई जटिलता वर्गों को परिभाषित किया गया है। एक कमी एक समस्या का दूसरी समस्या में परिवर्तन है। यह एक समस्या की अनौपचारिक धारणा को कम से कम एक और समस्या के रूप में मुश्किल बनाता है। उदाहरण के लिए, यदि कोई समस्या Y के लिए एल्गोरिथ्म का उपयोग करके X को हल किया जा सकता है, तो X, Y से अधिक कठिन नहीं है, और हम कहते हैं कि X, Y को कम कर देता है। कई अलग-अलग प्रकार के कटौती हैं, जिनके आधार पर कटौती की विधि, जैसे कि कुक रिडक्शन, कार्प रिडक्शन और लेविन रिडक्शन, और पोलिनेशन-टाइम रिडक्शन या लॉग-स्पेस रिडक्शन जैसी कटौती की जटिलता पर बाध्य होती है।   \n\n   answer_start             text  c_id  \\\n0           378  प्रकार के कटौती     0   \n\n                                                answers  \n0  {'answer_start': [378], 'text': ['प्रकार के कटौती']}  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer_start</th>\n      <th>text</th>\n      <th>c_id</th>\n      <th>answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56e1c9bfe3433e1400423196</td>\n      <td>बहुपद समय में कमी क्या इसका एक उदाहरण है?</td>\n      <td>कमी की अवधारणा का उपयोग करके कई जटिलता वर्गों को परिभाषित किया गया है। एक कमी एक समस्या का दूसरी समस्या में परिवर्तन है। यह एक समस्या की अनौपचारिक धारणा को कम से कम एक और समस्या के रूप में मुश्किल बनाता है। उदाहरण के लिए, यदि कोई समस्या Y के लिए एल्गोरिथ्म का उपयोग करके X को हल किया जा सकता है, तो X, Y से अधिक कठिन नहीं है, और हम कहते हैं कि X, Y को कम कर देता है। कई अलग-अलग प्रकार के कटौती हैं, जिनके आधार पर कटौती की विधि, जैसे कि कुक रिडक्शन, कार्प रिडक्शन और लेविन रिडक्शन, और पोलिनेशन-टाइम रिडक्शन या लॉग-स्पेस रिडक्शन जैसी कटौती की जटिलता पर बाध्य होती है।</td>\n      <td>378</td>\n      <td>प्रकार के कटौती</td>\n      <td>0</td>\n      <td>{'answer_start': [378], 'text': ['प्रकार के कटौती']}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dev.head()","metadata":{"id":"UtdMAejjoDwI","outputId":"b0972c68-05ce-483b-caec-8677fd583307","execution":{"iopub.status.busy":"2022-05-12T12:38:28.035905Z","iopub.execute_input":"2022-05-12T12:38:28.036158Z","iopub.status.idle":"2022-05-12T12:38:28.051434Z","shell.execute_reply.started":"2022-05-12T12:38:28.036123Z","shell.execute_reply":"2022-05-12T12:38:28.050649Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                      index  \\\n0  56e1c9bfe3433e1400423196   \n1  56be8e613aeaaa14008c90d1   \n2  5726378238643c19005ad315   \n3  5711619950c2381900b54ab3   \n4  572689b6dd62a815002e8893   \n\n                                                           question  \\\n0                         बहुपद समय में कमी क्या इसका एक उदाहरण है?   \n1                                     सुपर बाउल 50 का विषय क्या था?   \n2                    1967 में सिम्पोजियम में क्या सुझाव दिया गया था   \n3  एक वायुमंडलीय इंजन में, क्या के खिलाफ हवा के दबाव धक्का करता है?   \n4            यॉर्कशायर में किसकी ट्रेनें गंतव्यों की सेवा करती हैं?   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        context  \\\n0                                                                                                                                                                         कमी की अवधारणा का उपयोग करके कई जटिलता वर्गों को परिभाषित किया गया है। एक कमी एक समस्या का दूसरी समस्या में परिवर्तन है। यह एक समस्या की अनौपचारिक धारणा को कम से कम एक और समस्या के रूप में मुश्किल बनाता है। उदाहरण के लिए, यदि कोई समस्या Y के लिए एल्गोरिथ्म का उपयोग करके X को हल किया जा सकता है, तो X, Y से अधिक कठिन नहीं है, और हम कहते हैं कि X, Y को कम कर देता है। कई अलग-अलग प्रकार के कटौती हैं, जिनके आधार पर कटौती की विधि, जैसे कि कुक रिडक्शन, कार्प रिडक्शन और लेविन रिडक्शन, और पोलिनेशन-टाइम रिडक्शन या लॉग-स्पेस रिडक्शन जैसी कटौती की जटिलता पर बाध्य होती है।   \n1  सुपर बाउल 50, 2015 के सीज़न के लिए नेशनल फुटबॉल लीग (एनएफएल) के चैंपियन का निर्धारण करने के लिए एक अमेरिकी फुटबॉल खेल था। अमेरिकी फुटबॉल सम्मेलन (एएफसी) चैंपियन डेनवर ब्रोंकोस ने राष्ट्रीय फुटबॉल सम्मेलन (एनएफसी) चैंपियन कैरोलिना पैंथर्स को 24-10 से हराकर अपना तीसरा सुपर बाउल खिताब जीता। यह खेल 7 फरवरी, 2016 को कैलिफोर्निया के सांता क्लारा में सैन फ्रांसिस्को बे एरिया के लेवी स्टेडियम में खेला गया था। चूंकि यह 50 वां सुपर बाउल था, इसलिए लीग ने विभिन्न स्वर्ण-थीम वाली पहलों के साथ \"गोल्डन एनिवर्सरी\" पर जोर दिया, साथ ही रोमन सुपर के साथ प्रत्येक सुपर बाउल गेम के नामकरण की परंपरा को अस्थायी रूप से निलंबित कर दिया (जिसके तहत गेम को \"सुपर बाउल एल\" के रूप में जाना जाता था), ताकि लोगो को अरबी अंकों की संख्या 50 की सुविधा मिल सके।   \n2                                                                                                                                                                        1965 में, यूके की नेशनल फिजिकल लेबोरेटरी में डोनाल्ड डेविस ने स्वतंत्र रूप से बारान द्वारा विकसित मैसेज रूटिंग पद्धति को विकसित किया। उन्होंने इसे पैकेट स्विचिंग, बारन की तुलना में अधिक सुलभ नाम कहा, और यूके में एक राष्ट्रव्यापी नेटवर्क बनाने का प्रस्ताव दिया। उन्होंने 1966 में प्रस्ताव पर अपनी बात रखी, जिसके बाद रक्षा मंत्रालय (MoD) के एक व्यक्ति ने उन्हें बारां के काम के बारे में बताया। डेविस की टीम (रोजर स्कैंटेबरी) के एक सदस्य ने लॉरेंस रॉबर्ट्स से 1967 एसीएम संगोष्ठी में ऑपरेटिंग सिस्टम सिद्धांत पर मुलाकात की और ने इसे ARPANET में उपयोग के लिए सुझाव दिया।   \n3                                                                                                                                                                                                                        अगला प्रमुख कदम तब हुआ जब जेम्स वाट ने एक अलग कंडेनसर के साथ न्यूकमेन के इंजन का एक उन्नत संस्करण विकसित किया (1763–1775)। बॉल्टन और वाट के शुरुआती इंजनों ने जॉन स्मेटन के न्यूकमेन के उन्नत संस्करण के रूप में आधे कोयले का इस्तेमाल किया। न्यूकमेन और वाट के शुरुआती इंजन \"वायुमंडलीय\" थे। वे वाष्प के विस्तार के दबाव के बजाय भाप को संघनित करके उत्पन्न आंशिक निर्वात में एक पिस्टन धकेलने वाले वायु दबाव से संचालित होते थे। इंजन सिलेंडरों को बड़ा होना था क्योंकि वायुमंडलीय दबाव के कारण उन पर कार्य करने वाला एकमात्र बल था।   \n4                                                                                                                                ट्रेन ऑपरेटर वर्जिन ट्रेन ईस्ट कोस्ट तीन घंटे की यात्रा के समय के साथ, लंदन किंग्स क्रॉस करने के लिए ट्रेनों की एक आधा प्रति घंटा की आवृत्ति प्रदान करता है, इन सेवाओं के साथ स्कॉटलैंड के लिए डरहम, Darlington, यॉर्क, Doncaster, नेवार्क उत्तरी गेट और पीटरबरो और उत्तर में फोन एडिनबर्ग में कॉल करने वाली सभी ट्रेनें और गाड़ियों की एक छोटी संख्या ग्लासगो, एबरडीन और इनवर्नेस तक बढ़ गई। क्रॉसकाउंट्री ट्रेनें यॉर्कशायर, मिडलैंड्स और दक्षिण पश्चिम में गंतव्यों की सेवा करती हैं। सबसे पहले TransPennine एक्सप्रेस मैनचेस्टर और लिवरपूल के लिए सेवाएं चल रही है। उत्तरी रेल स्थानीय और क्षेत्रीय सेवाएं प्रदान करता है।   \n\n   answer_start               text  c_id  \\\n0           378    प्रकार के कटौती     0   \n1           485  \"गोल्डन एनिवर्सरी     1   \n2           523     ने इसे ARPANET     2   \n3           367          एक पिस्टन     3   \n4           382      क्रॉसकाउंट्री     4   \n\n                                                  answers  \n0    {'answer_start': [378], 'text': ['प्रकार के कटौती']}  \n1  {'answer_start': [485], 'text': ['\"गोल्डन एनिवर्सरी']}  \n2     {'answer_start': [523], 'text': ['ने इसे ARPANET']}  \n3          {'answer_start': [367], 'text': ['एक पिस्टन']}  \n4      {'answer_start': [382], 'text': ['क्रॉसकाउंट्री']}  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>question</th>\n      <th>context</th>\n      <th>answer_start</th>\n      <th>text</th>\n      <th>c_id</th>\n      <th>answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56e1c9bfe3433e1400423196</td>\n      <td>बहुपद समय में कमी क्या इसका एक उदाहरण है?</td>\n      <td>कमी की अवधारणा का उपयोग करके कई जटिलता वर्गों को परिभाषित किया गया है। एक कमी एक समस्या का दूसरी समस्या में परिवर्तन है। यह एक समस्या की अनौपचारिक धारणा को कम से कम एक और समस्या के रूप में मुश्किल बनाता है। उदाहरण के लिए, यदि कोई समस्या Y के लिए एल्गोरिथ्म का उपयोग करके X को हल किया जा सकता है, तो X, Y से अधिक कठिन नहीं है, और हम कहते हैं कि X, Y को कम कर देता है। कई अलग-अलग प्रकार के कटौती हैं, जिनके आधार पर कटौती की विधि, जैसे कि कुक रिडक्शन, कार्प रिडक्शन और लेविन रिडक्शन, और पोलिनेशन-टाइम रिडक्शन या लॉग-स्पेस रिडक्शन जैसी कटौती की जटिलता पर बाध्य होती है।</td>\n      <td>378</td>\n      <td>प्रकार के कटौती</td>\n      <td>0</td>\n      <td>{'answer_start': [378], 'text': ['प्रकार के कटौती']}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>56be8e613aeaaa14008c90d1</td>\n      <td>सुपर बाउल 50 का विषय क्या था?</td>\n      <td>सुपर बाउल 50, 2015 के सीज़न के लिए नेशनल फुटबॉल लीग (एनएफएल) के चैंपियन का निर्धारण करने के लिए एक अमेरिकी फुटबॉल खेल था। अमेरिकी फुटबॉल सम्मेलन (एएफसी) चैंपियन डेनवर ब्रोंकोस ने राष्ट्रीय फुटबॉल सम्मेलन (एनएफसी) चैंपियन कैरोलिना पैंथर्स को 24-10 से हराकर अपना तीसरा सुपर बाउल खिताब जीता। यह खेल 7 फरवरी, 2016 को कैलिफोर्निया के सांता क्लारा में सैन फ्रांसिस्को बे एरिया के लेवी स्टेडियम में खेला गया था। चूंकि यह 50 वां सुपर बाउल था, इसलिए लीग ने विभिन्न स्वर्ण-थीम वाली पहलों के साथ \"गोल्डन एनिवर्सरी\" पर जोर दिया, साथ ही रोमन सुपर के साथ प्रत्येक सुपर बाउल गेम के नामकरण की परंपरा को अस्थायी रूप से निलंबित कर दिया (जिसके तहत गेम को \"सुपर बाउल एल\" के रूप में जाना जाता था), ताकि लोगो को अरबी अंकों की संख्या 50 की सुविधा मिल सके।</td>\n      <td>485</td>\n      <td>\"गोल्डन एनिवर्सरी</td>\n      <td>1</td>\n      <td>{'answer_start': [485], 'text': ['\"गोल्डन एनिवर्सरी']}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5726378238643c19005ad315</td>\n      <td>1967 में सिम्पोजियम में क्या सुझाव दिया गया था</td>\n      <td>1965 में, यूके की नेशनल फिजिकल लेबोरेटरी में डोनाल्ड डेविस ने स्वतंत्र रूप से बारान द्वारा विकसित मैसेज रूटिंग पद्धति को विकसित किया। उन्होंने इसे पैकेट स्विचिंग, बारन की तुलना में अधिक सुलभ नाम कहा, और यूके में एक राष्ट्रव्यापी नेटवर्क बनाने का प्रस्ताव दिया। उन्होंने 1966 में प्रस्ताव पर अपनी बात रखी, जिसके बाद रक्षा मंत्रालय (MoD) के एक व्यक्ति ने उन्हें बारां के काम के बारे में बताया। डेविस की टीम (रोजर स्कैंटेबरी) के एक सदस्य ने लॉरेंस रॉबर्ट्स से 1967 एसीएम संगोष्ठी में ऑपरेटिंग सिस्टम सिद्धांत पर मुलाकात की और ने इसे ARPANET में उपयोग के लिए सुझाव दिया।</td>\n      <td>523</td>\n      <td>ने इसे ARPANET</td>\n      <td>2</td>\n      <td>{'answer_start': [523], 'text': ['ने इसे ARPANET']}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5711619950c2381900b54ab3</td>\n      <td>एक वायुमंडलीय इंजन में, क्या के खिलाफ हवा के दबाव धक्का करता है?</td>\n      <td>अगला प्रमुख कदम तब हुआ जब जेम्स वाट ने एक अलग कंडेनसर के साथ न्यूकमेन के इंजन का एक उन्नत संस्करण विकसित किया (1763–1775)। बॉल्टन और वाट के शुरुआती इंजनों ने जॉन स्मेटन के न्यूकमेन के उन्नत संस्करण के रूप में आधे कोयले का इस्तेमाल किया। न्यूकमेन और वाट के शुरुआती इंजन \"वायुमंडलीय\" थे। वे वाष्प के विस्तार के दबाव के बजाय भाप को संघनित करके उत्पन्न आंशिक निर्वात में एक पिस्टन धकेलने वाले वायु दबाव से संचालित होते थे। इंजन सिलेंडरों को बड़ा होना था क्योंकि वायुमंडलीय दबाव के कारण उन पर कार्य करने वाला एकमात्र बल था।</td>\n      <td>367</td>\n      <td>एक पिस्टन</td>\n      <td>3</td>\n      <td>{'answer_start': [367], 'text': ['एक पिस्टन']}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>572689b6dd62a815002e8893</td>\n      <td>यॉर्कशायर में किसकी ट्रेनें गंतव्यों की सेवा करती हैं?</td>\n      <td>ट्रेन ऑपरेटर वर्जिन ट्रेन ईस्ट कोस्ट तीन घंटे की यात्रा के समय के साथ, लंदन किंग्स क्रॉस करने के लिए ट्रेनों की एक आधा प्रति घंटा की आवृत्ति प्रदान करता है, इन सेवाओं के साथ स्कॉटलैंड के लिए डरहम, Darlington, यॉर्क, Doncaster, नेवार्क उत्तरी गेट और पीटरबरो और उत्तर में फोन एडिनबर्ग में कॉल करने वाली सभी ट्रेनें और गाड़ियों की एक छोटी संख्या ग्लासगो, एबरडीन और इनवर्नेस तक बढ़ गई। क्रॉसकाउंट्री ट्रेनें यॉर्कशायर, मिडलैंड्स और दक्षिण पश्चिम में गंतव्यों की सेवा करती हैं। सबसे पहले TransPennine एक्सप्रेस मैनचेस्टर और लिवरपूल के लिए सेवाएं चल रही है। उत्तरी रेल स्थानीय और क्षेत्रीय सेवाएं प्रदान करता है।</td>\n      <td>382</td>\n      <td>क्रॉसकाउंट्री</td>\n      <td>4</td>\n      <td>{'answer_start': [382], 'text': ['क्रॉसकाउंट्री']}</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tds = Dataset.from_pandas(train)\nvds = Dataset.from_pandas(dev)\n\n\nsquad = DatasetDict()\n\nsquad['train'] = tds\nsquad['validation'] = vds","metadata":{"id":"IIK5Iy_OoDwJ","execution":{"iopub.status.busy":"2022-05-12T12:38:28.052944Z","iopub.execute_input":"2022-05-12T12:38:28.053353Z","iopub.status.idle":"2022-05-12T12:38:29.276572Z","shell.execute_reply.started":"2022-05-12T12:38:28.053313Z","shell.execute_reply":"2022-05-12T12:38:29.275821Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"squad","metadata":{"id":"0F7WoQnEoDwK","outputId":"998837f5-8165-4dc6-d429-f3225d91ac6b","execution":{"iopub.status.busy":"2022-05-12T12:38:29.280839Z","iopub.execute_input":"2022-05-12T12:38:29.284037Z","iopub.status.idle":"2022-05-12T12:38:29.292835Z","shell.execute_reply.started":"2022-05-12T12:38:29.283991Z","shell.execute_reply":"2022-05-12T12:38:29.292171Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['index', 'question', 'context', 'answer_start', 'text', 'c_id', 'answers'],\n        num_rows: 85804\n    })\n    validation: Dataset({\n        features: ['index', 'question', 'context', 'answer_start', 'text', 'c_id', 'answers'],\n        num_rows: 34111\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\n\npretraining_language = 'hi'\n# model = AutoModelForQuestionAnswering.from_pretrained(\"microsoft/Multilingual-MiniLM-L12-H384\")\nmodel = AutoModelForQuestionAnswering.from_pretrained(f\"subhasisj/{pretraining_language}-TAPT-MLM-MiniLM\")\ntokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")","metadata":{"id":"Gx-aVAWVoDwK","outputId":"35a2721f-5139-478e-d2ab-f91bd7432e4d","execution":{"iopub.status.busy":"2022-05-12T12:38:29.297168Z","iopub.execute_input":"2022-05-12T12:38:29.299326Z","iopub.status.idle":"2022-05-12T12:39:00.408830Z","shell.execute_reply.started":"2022-05-12T12:38:29.299286Z","shell.execute_reply":"2022-05-12T12:39:00.408022Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/686 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16737d79158c494c9e242b2e9f1040f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/450M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca24f8344bd84d0fb2974dfb9724257b"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at subhasisj/hi-TAPT-MLM-MiniLM were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForQuestionAnswering were not initialized from the model checkpoint at subhasisj/hi-TAPT-MLM-MiniLM and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7067dedf2354353accc8f2ae10125a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4df9a57003764291bbd7b862e9d98efc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a300fba8e68d48c6b7dbcc29bcfbaf0f"}},"metadata":{}}]},{"cell_type":"code","source":"pad_on_right = tokenizer.padding_side == \"right\"\nmax_length = 384 # The maximum length of a feature (question and context)\ndoc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.\ndef prepare_train_features(examples):\n    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n    # left whitespace\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n    # in one example possible giving several features when a context is long, each of those features having a\n    # context that overlaps a bit the context of the previous feature.\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # Since one example might give us several features if it has a long context, we need a map from a feature to\n    # its corresponding example. This key gives us just that.\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    # The offset mappings will give us a map from token to character position in the original context. This will\n    # help us compute the start_positions and end_positions.\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n\n    # Let's label those examples!\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        # We will label impossible answers with the index of the CLS token.\n        input_ids = tokenized_examples[\"input_ids\"][i]\n        cls_index = input_ids.index(tokenizer.cls_token_id)\n\n        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n        sequence_ids = tokenized_examples.sequence_ids(i)\n\n        # One example can give several spans, this is the index of the example containing this span of text.\n        sample_index = sample_mapping[i]\n        answers = examples[\"answers\"][sample_index]\n        # If no answers are given, set the cls_index as answer.\n        if len(answers[\"answer_start\"]) == 0:\n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n        else:\n            # Start/end character index of the answer in the text.\n            start_char = answers[\"answer_start\"][0]\n            end_char = start_char + len(answers[\"text\"][0])\n\n            # Start token index of the current span in the text.\n            token_start_index = 0\n            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n                token_start_index += 1\n\n            # End token index of the current span in the text.\n            token_end_index = len(input_ids) - 1\n            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n                token_end_index -= 1\n\n            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n                tokenized_examples[\"start_positions\"].append(cls_index)\n                tokenized_examples[\"end_positions\"].append(cls_index)\n            else:\n                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n                # Note: we could go after the last offset if the answer is the last word (edge case).\n                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                    token_start_index += 1\n                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n                while offsets[token_end_index][1] >= end_char:\n                    token_end_index -= 1\n                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n\n    return tokenized_examples\n\ndef prepare_validation_features(examples):\n    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n    # left whitespace\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n    # in one example possible giving several features when a context is long, each of those features having a\n    # context that overlaps a bit the context of the previous feature.\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # Since one example might give us several features if it has a long context, we need a map from a feature to\n    # its corresponding example. This key gives us just that.\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n\n    # We keep the example_id that gave us this feature and we will store the offset mappings.\n    tokenized_examples[\"example_id\"] = []\n\n    for i in range(len(tokenized_examples[\"input_ids\"])):\n        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        context_index = 1 if pad_on_right else 0\n\n        # One example can give several spans, this is the index of the example containing this span of text.\n        sample_index = sample_mapping[i]\n        tokenized_examples[\"example_id\"].append(examples[\"index\"][sample_index])\n\n        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n        # position is part of the context or not.\n        tokenized_examples[\"offset_mapping\"][i] = [\n            (o if sequence_ids[k] == context_index else None)\n            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n        ]\n\n    return tokenized_examples","metadata":{"id":"LyTyDfJUoDwL","execution":{"iopub.status.busy":"2022-05-12T12:39:00.410459Z","iopub.execute_input":"2022-05-12T12:39:00.410723Z","iopub.status.idle":"2022-05-12T12:39:00.432394Z","shell.execute_reply.started":"2022-05-12T12:39:00.410689Z","shell.execute_reply":"2022-05-12T12:39:00.431618Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"batch_size = 32","metadata":{"id":"sy-2gbptoDwM","execution":{"iopub.status.busy":"2022-05-12T12:39:00.435230Z","iopub.execute_input":"2022-05-12T12:39:00.435726Z","iopub.status.idle":"2022-05-12T12:39:00.443824Z","shell.execute_reply.started":"2022-05-12T12:39:00.435686Z","shell.execute_reply":"2022-05-12T12:39:00.442840Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"squad = squad.map(prepare_train_features,batched=True,remove_columns=squad[\"train\"].column_names)","metadata":{"id":"K_rmHgEsoDwM","outputId":"7737a283-c97d-4e75-8a0a-63aa7b139916","execution":{"iopub.status.busy":"2022-05-12T12:39:00.445466Z","iopub.execute_input":"2022-05-12T12:39:00.446094Z","iopub.status.idle":"2022-05-12T12:41:21.148695Z","shell.execute_reply.started":"2022-05-12T12:39:00.446050Z","shell.execute_reply":"2022-05-12T12:41:21.147911Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/86 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c7cf99e75bc4cbc809881e619943a62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/35 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cb2373eac844894a946ac0a0d089d91"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"id":"KEEJXUIKsHm1","outputId":"45a9a477-876c-4f07-9e11-5b748f89db56","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\nargs = TrainingArguments(\n    f\"./{pretraining_language}-finetuned-squad-qa-minilmv2-{batch_size}\",\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate = 3e-5,\n    per_device_train_batch_size = batch_size,\n    per_device_eval_batch_size = batch_size,\n    warmup_ratio = 0.1,\n    gradient_accumulation_steps = 8,\n    num_train_epochs = 5,\n    fp16=True,\n    weight_decay = 0.01,\n#     push_to_hub=True,\n    save_total_limit=1,\n    load_best_model_at_end=True\n)","metadata":{"id":"Dbe50ff6oDwN","execution":{"iopub.status.busy":"2022-05-12T12:41:21.149878Z","iopub.execute_input":"2022-05-12T12:41:21.151042Z","iopub.status.idle":"2022-05-12T12:41:21.969466Z","shell.execute_reply.started":"2022-05-12T12:41:21.151001Z","shell.execute_reply":"2022-05-12T12:41:21.968646Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from transformers import default_data_collator\n\ndata_collator = default_data_collator","metadata":{"id":"8qlIMf3-oDwN","execution":{"iopub.status.busy":"2022-05-12T12:41:21.971959Z","iopub.execute_input":"2022-05-12T12:41:21.972407Z","iopub.status.idle":"2022-05-12T12:41:21.976178Z","shell.execute_reply.started":"2022-05-12T12:41:21.972365Z","shell.execute_reply":"2022-05-12T12:41:21.975391Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=squad[\"train\"],\n    eval_dataset=squad[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"id":"g8ThBRtloDwN","outputId":"6ec5e5a7-a593-437b-eed3-0d7288894da6","execution":{"iopub.status.busy":"2022-05-12T12:41:21.977837Z","iopub.execute_input":"2022-05-12T12:41:21.978411Z","iopub.status.idle":"2022-05-12T12:41:27.786464Z","shell.execute_reply.started":"2022-05-12T12:41:21.978370Z","shell.execute_reply":"2022-05-12T12:41:27.785408Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stderr","text":"Using amp half precision backend\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"LtnGrNAMoDwO","outputId":"32e467a3-19d7-4844-cbb9-6977e884c978","execution":{"iopub.status.busy":"2022-05-12T12:41:27.789465Z","iopub.execute_input":"2022-05-12T12:41:27.789683Z","iopub.status.idle":"2022-05-12T15:21:16.600212Z","shell.execute_reply.started":"2022-05-12T12:41:27.789655Z","shell.execute_reply":"2022-05-12T15:21:16.599228Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"***** Running training *****\n  Num examples = 91554\n  Num Epochs = 5\n  Instantaneous batch size per device = 32\n  Total train batch size (w. parallel, distributed & accumulation) = 256\n  Gradient Accumulation steps = 8\n  Total optimization steps = 1785\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.12.16 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.15"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20220512_124142-1wgxer06</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/subhasisj/huggingface/runs/1wgxer06\" target=\"_blank\">./hi-finetuned-squad-qa-minilmv2-32</a></strong> to <a href=\"https://wandb.ai/subhasisj/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1785' max='1785' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1785/1785 2:39:21, Epoch 4/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>2.488162</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>3.247600</td>\n      <td>1.928413</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.883100</td>\n      <td>1.747219</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.883100</td>\n      <td>1.686448</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.565400</td>\n      <td>1.677973</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 37015\n  Batch size = 32\nSaving model checkpoint to ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-357\nConfiguration saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-357/config.json\nModel weights saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-357/pytorch_model.bin\ntokenizer config file saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-357/tokenizer_config.json\nSpecial tokens file saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-357/special_tokens_map.json\n***** Running Evaluation *****\n  Num examples = 37015\n  Batch size = 32\nSaving model checkpoint to ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-714\nConfiguration saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-714/config.json\nModel weights saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-714/pytorch_model.bin\ntokenizer config file saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-714/tokenizer_config.json\nSpecial tokens file saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-714/special_tokens_map.json\n***** Running Evaluation *****\n  Num examples = 37015\n  Batch size = 32\nSaving model checkpoint to ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1071\nConfiguration saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1071/config.json\nModel weights saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1071/pytorch_model.bin\ntokenizer config file saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1071/tokenizer_config.json\nSpecial tokens file saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1071/special_tokens_map.json\nDeleting older checkpoint [hi-finetuned-squad-qa-minilmv2-32/checkpoint-357] due to args.save_total_limit\nwandb: Network error (ReadTimeout), entering retry loop.\n***** Running Evaluation *****\n  Num examples = 37015\n  Batch size = 32\nSaving model checkpoint to ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428\nConfiguration saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/config.json\nModel weights saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/pytorch_model.bin\ntokenizer config file saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/tokenizer_config.json\nSpecial tokens file saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/special_tokens_map.json\nDeleting older checkpoint [hi-finetuned-squad-qa-minilmv2-32/checkpoint-714] due to args.save_total_limit\n***** Running Evaluation *****\n  Num examples = 37015\n  Batch size = 32\nSaving model checkpoint to ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785\nConfiguration saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/config.json\nModel weights saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/pytorch_model.bin\ntokenizer config file saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/tokenizer_config.json\nSpecial tokens file saved in ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/special_tokens_map.json\nDeleting older checkpoint [hi-finetuned-squad-qa-minilmv2-32/checkpoint-1071] due to args.save_total_limit\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from ./hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785 (score: 1.6779732704162598).\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1785, training_loss=2.110068766276042, metrics={'train_runtime': 9587.4956, 'train_samples_per_second': 47.747, 'train_steps_per_second': 0.186, 'total_flos': 2.245204423629619e+16, 'train_loss': 2.110068766276042, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(\"Training Completed.\")","metadata":{"id":"9u9xbeOgoDwO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_features = squad[\"validation\"]","metadata":{"id":"4rCmwUA2oDwO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation_features = squad_valid.map(\n#     prepare_validation_features,\n#     batched=True,\n#     remove_columns=squad_valid.column_names\n# )","metadata":{"id":"t9NzrkpioDwO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -zcvf hi-finetuned-squad-qa-minilmv2-32.tar.gz /kaggle/working/hi-finetuned-squad-qa-minilmv2-32/","metadata":{"execution":{"iopub.status.busy":"2022-05-12T15:21:31.771479Z","iopub.execute_input":"2022-05-12T15:21:31.773508Z","iopub.status.idle":"2022-05-12T15:22:54.016371Z","shell.execute_reply.started":"2022-05-12T15:21:31.773450Z","shell.execute_reply":"2022-05-12T15:22:54.015405Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\ntar: Removing leading `/' from member names\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/sentencepiece.bpe.model\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/training_args.bin\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/pytorch_model.bin\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/config.json\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/tokenizer.json\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/special_tokens_map.json\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/trainer_state.json\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/optimizer.pt\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/rng_state.pth\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/tokenizer_config.json\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/scaler.pt\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1785/scheduler.pt\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/sentencepiece.bpe.model\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/training_args.bin\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/pytorch_model.bin\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/config.json\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/tokenizer.json\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/special_tokens_map.json\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/trainer_state.json\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/optimizer.pt\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/rng_state.pth\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/tokenizer_config.json\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/scaler.pt\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/checkpoint-1428/scheduler.pt\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/runs/\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/runs/May12_12-41-21_e8d6f542cd1f/\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/runs/May12_12-41-21_e8d6f542cd1f/events.out.tfevents.1652359287.e8d6f542cd1f.95.0\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/runs/May12_12-41-21_e8d6f542cd1f/1652359287.8453972/\n/kaggle/working/hi-finetuned-squad-qa-minilmv2-32/runs/May12_12-41-21_e8d6f542cd1f/1652359287.8453972/events.out.tfevents.1652359287.e8d6f542cd1f.95.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\n\nFileLink(r'./hi-finetuned-squad-qa-minilmv2-32.tar.gz')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T15:23:06.680073Z","iopub.execute_input":"2022-05-12T15:23:06.680359Z","iopub.status.idle":"2022-05-12T15:23:06.693697Z","shell.execute_reply.started":"2022-05-12T15:23:06.680326Z","shell.execute_reply":"2022-05-12T15:23:06.692893Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/hi-finetuned-squad-qa-minilmv2-32.tar.gz","text/html":"<a href='./hi-finetuned-squad-qa-minilmv2-32.tar.gz' target='_blank'>./hi-finetuned-squad-qa-minilmv2-32.tar.gz</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\nfrom IPython.display import FileLink\nFileLink(f\"./{pretraining_language}-finetuned-squad-qa-minilmv2-{batch_size}/pytorch_model.bin\"')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(f\"./{pretraining_language}-finetuned-squad-qa-minilmv2-{batch_size}/config.json\"')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(f\"./{pretraining_language}-finetuned-squad-qa-minilmv2-{batch_size}/tokenizer_config.json\"')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(f\"./{pretraining_language}-finetuned-squad-qa-minilmv2-{batch_size}/special_tokens_map.json\"')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_predictions = trainer.predict(validation_features)","metadata":{"id":"kXIgFsSRoDwP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))","metadata":{"id":"zCryGMeKoDwP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import collections\n\nexamples = squad_valid\nfeatures = validation_features\n\nexample_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\nfeatures_per_example = collections.defaultdict(list)\nfor i, feature in enumerate(features):\n    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)","metadata":{"id":"O8y6KQSfoDwP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n    all_start_logits, all_end_logits = raw_predictions\n    # Build a map example to its corresponding features.\n    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n    features_per_example = collections.defaultdict(list)\n    for i, feature in enumerate(features):\n        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n\n    # The dictionaries we have to fill.\n    predictions = collections.OrderedDict()\n\n    # Logging.\n    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n\n    # Let's loop over all the examples!\n    for example_index, example in enumerate(tqdm(examples)):\n        # Those are the indices of the features associated to the current example.\n        feature_indices = features_per_example[example_index]\n\n        min_null_score = None # Only used if squad_v2 is True.\n        valid_answers = []\n        \n        context = example[\"context\"]\n        # Looping through all the features associated to the current example.\n        for feature_index in feature_indices:\n            # We grab the predictions of the model for this feature.\n            start_logits = all_start_logits[feature_index]\n            end_logits = all_end_logits[feature_index]\n            # This is what will allow us to map some the positions in our logits to span of texts in the original\n            # context.\n            offset_mapping = features[feature_index][\"offset_mapping\"]\n\n            # Update minimum null prediction.\n            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n            if min_null_score is None or min_null_score < feature_null_score:\n                min_null_score = feature_null_score\n\n            # Go through all possibilities for the `n_best_size` greater start and end logits.\n            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n                    # to part of the input_ids that are not in the context.\n                    if (\n                        start_index >= len(offset_mapping)\n                        or end_index >= len(offset_mapping)\n                        or offset_mapping[start_index] is None\n                        or offset_mapping[end_index] is None\n                        or offset_mapping[start_index] == []\n                        or offset_mapping[end_index] == []\n                    ):\n                        continue\n                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n                        continue\n\n                    start_char = offset_mapping[start_index][0]\n                    end_char = offset_mapping[end_index][1]\n                    valid_answers.append(\n                        {\n                            \"score\": start_logits[start_index] + end_logits[end_index],\n                            \"text\": context[start_char: end_char]\n                        }\n                    )\n        \n        if len(valid_answers) > 0:\n            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n        else:\n            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n            # failure.\n            best_answer = {\"text\": \"\", \"score\": 0.0}\n        \n        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n        # if not squad_v2:\n            # predictions[example[\"id\"]] = best_answer[\"text\"]\n        # else:\n        answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n        predictions[example[\"id\"]] = answer\n\n    return predictions","metadata":{"id":"KoWxjPKaoDwP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = postprocess_qa_predictions(squad_valid, validation_features, raw_predictions.predictions)\n","metadata":{"id":"sn0mipzqoDwQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\nmetric = load_metric(\"squad\")","metadata":{"id":"RMNy31HyoDwQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\nreferences = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in squad_valid]\nmetric.compute(predictions=formatted_predictions, references=references)","metadata":{"id":"ERR0PihNoDwQ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}